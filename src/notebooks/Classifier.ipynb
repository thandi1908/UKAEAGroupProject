{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33210b17",
   "metadata": {},
   "source": [
    "### Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aa0b0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecc2e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2cf0fb",
   "metadata": {},
   "source": [
    "### Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd1c6aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle(\"/share/rcifdata/jbarr/UKAEAGroupProject/data/train_data.pkl\")\n",
    "\n",
    "X_train, Y_train = train_data.iloc[:,:-1].to_numpy(), train_data.iloc[:,-1].to_numpy()\n",
    "\n",
    "validation_data = pd.read_pickle(\"/share/rcifdata/jbarr/UKAEAGroupProject/data/validation_data.pkl\")\n",
    "\n",
    "X_val, Y_val = validation_data.iloc[:,:-1].to_numpy(), validation_data.iloc[:,-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb9c2a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "x_train = scaler.transform(X_train)\n",
    "x_val = scaler.transform (X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2406bbaa",
   "metadata": {},
   "source": [
    "###  Best Neural Network Classifier From Initial Grid Search\n",
    "\n",
    "**Initial Grid Search Parameters**\n",
    "\n",
    "Number of nodes: [5,10, 20, 30]\n",
    "\n",
    "Number of layers: [2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b51adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/share/rcifdata/jbarr/UKAEAGroupProject/grid_search/'\n",
    "trainings = []\n",
    "for i in range(336):\n",
    "    trial_dict = pickle.load(open(file_path+\"trial_\"+str(i)+\".pkl\", 'rb'))\n",
    "    trainings.append(trial_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8625509",
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculate the number of parameters\n",
    "def model_params(nodes, n_inputs=15):\n",
    "    nodes.append(1)\n",
    "    params = 0\n",
    "    \n",
    "    # bottle neck, 0 if model doesn't include a bottle neck and 1 if the model does include one.\n",
    "    bottle_in = 0\n",
    "    bottle_hidden = 0\n",
    "    \n",
    "    # parameters from models\n",
    "    for i in range(len(nodes)):\n",
    "        if i == 0:\n",
    "            if nodes[i] < n_inputs: bottle_in = 1\n",
    "            params += n_inputs * nodes[i]\n",
    "        else:\n",
    "            params += nodes[i-1]* nodes[i]\n",
    "            \n",
    "            if nodes[i-1] < nodes[i]: bottle_hidden = 1\n",
    "    \n",
    "    # parameters from biases\n",
    "    for i in nodes: \n",
    "        params += i\n",
    "    return params, bottle_in, bottle_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2add51",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model_params([2,2])[0] == 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937a13a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best architecture\n",
    "best_trial = None \n",
    "best_val_acc = - sys.float_info.max\n",
    "val_accs = []\n",
    "n_params = []\n",
    "bottle_in = []\n",
    "bottle_hid = []\n",
    "\n",
    "for trial in trainings:\n",
    "    val_acc = trial[\"perfomance\"][1]\n",
    "    \n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    n_param, bot_in, bot_hid  = model_params(list(trial['nodes']))\n",
    "    \n",
    "    n_params.append(n_param)\n",
    "    \n",
    "    bottle_in.append(bot_in)\n",
    "    bottle_hid.append(bot_hid)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if val_acc > best_val_acc: \n",
    "        best_val_acc = val_acc\n",
    "        best_trial = trial\n",
    "        \n",
    "n_params = np.array(n_params)\n",
    "bottle_in = np.array(bottle_in)\n",
    "bottle_hid= np.array(bottle_hid)\n",
    "val_accs = np.array(val_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb7613",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Model\\n\")\n",
    "print(\"Network:\",best_trial[\"nodes\"],\"\\n\" )\n",
    "print(\"Validation accuracy:\", best_trial['perfomance'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6c819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(best_trial[\"history\"][\"acc\"],color = 'blue')\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ec0258",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(best_trial[\"history\"][\"loss\"], color = 'blue')\n",
    "plt.title(\"Trainign Loss Curve\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b26d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(val_accs, bins = 20, color = 'purple');\n",
    "plt.xlabel(\"Validation Accuracy\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754a7a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(n_params[np.where(bottle_in == 0)], val_accs[np.where(bottle_in == 0)], '.', label = 'Normal')\n",
    "plt.plot(n_params[np.where(bottle_in == 1)], val_accs[np.where(bottle_in == 1)], '.', label = 'Input bn')\n",
    "plt.plot(n_params[np.where(bottle_hid == 1)], val_accs[np.where(bottle_hid == 1)], '.', label = 'Hidden bn')\n",
    "plt.xlabel(\"Number of Model Parameters\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18029aa4",
   "metadata": {},
   "source": [
    "### Grid Search Conclusion\n",
    "\n",
    "Looking at the plot above we can see that increasing the number of model parameters in general leads to an increase in the models validation accuracy, the graph looks as though it will plateau, but it also suggestes we haven't hit the peak, a further grid search of models with a higher number of parameters should be conducted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637a2ce8",
   "metadata": {},
   "source": [
    "### Final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdd9bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_classifier():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(30, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(30, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(30, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')   \n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd72645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de731df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss ='binary_crossentropy', metrics = 'acc')\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45621c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, Y_train, validation_data = (x_val, Y_val), batch_size = 4096, epochs =50, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba4c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('saved_model/classifier_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f6582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ac323",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['acc'], 'o', label = 'Train acc')\n",
    "plt.plot(history.history['val_acc'], 'o', label = 'Val acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56127d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'], 'o', label = 'Train loss')\n",
    "plt.plot(history.history['val_loss'], 'o', label = 'Val loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e398f7d9",
   "metadata": {},
   "source": [
    "### Evaluate Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7648b33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25260b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_pickle(\"/share/rcifdata/jbarr/UKAEAGroupProject/data/test_data.pkl\")\n",
    "\n",
    "X_test, Y_test = test_data.iloc[:,:-1].to_numpy(), test_data.iloc[:,-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdb9b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f92687",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831a5a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "auc = roc_auc_score(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ca55ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "random_class = np.arange(0,1,0.005)\n",
    "plt.plot(random_class, random_class, '--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('Flase Negative Rate')\n",
    "plt.text(0.8, 0.2, f'auc = {auc: .2f}', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cfb505",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = np.where(predictions < 0.5, predictions, 1)\n",
    "test_pred = np.where(predictions >= 0.5, test_pred, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86457a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_positive = np.where(Y_test ==0)[0].shape[0]\n",
    "n_negative = np.where(Y_test ==1)[0].shape[0]\n",
    "div_arr = np.array([[n_positive, n_negative]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12713400",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mat = confusion_matrix(Y_test, test_pred, labels =[0,1])/div_arr\n",
    "sns.heatmap(con_mat, annot=True).set(title='Confusion Matrix', xlabel='Predicted', ylabel='Actual');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc73e3fd",
   "metadata": {},
   "source": [
    "### Distributions from classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea3e9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.round(predictions).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d485338",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_output = x_test[np.where(preds == 0)]\n",
    "yes_output = x_test[np.where(preds == 1)] \n",
    "assert no_output.shape[0] + yes_output.shape[0] == x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96807ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(train_data.iloc[:,:-1].columns)\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcb7b4e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, column in enumerate(columns):\n",
    "    # find the mean and std \n",
    "    mean_no, mean_yes = np.mean(no_output[:,i]), np.mean(yes_output[:,i])\n",
    "    std_no, std_yes = np.std(no_output[:,i]), np.std(yes_output[:,i])\n",
    "    \n",
    "    no_lower, no_upper = (mean_no - 3*std_no), (mean_no + 3*std_no)\n",
    "    yes_lower, yes_upper = (mean_yes - 3*std_yes), (mean_yes + 3*std_yes)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.hist(no_output[:,i], histtype = 'step', color = 'lime',\n",
    "             label =\" No output\", density = True, bins =50, range = (no_lower, no_upper));\n",
    "    \n",
    "    plt.hist(yes_output[:,i], histtype = 'step', color = 'purple',\n",
    "             label = \"Output\", density = True, bins = 50, range = (yes_lower,yes_upper ));\n",
    "    plt.legend()\n",
    "    plt.xlabel(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7298e5c4",
   "metadata": {},
   "source": [
    "# Train model with varying number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b368b3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_classifier_big():\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')   \n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1554d8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_indices = np.random.choice(x_val.shape[0], size = 100_000, replace=False)\n",
    "x_val_sample = x_val[val_indices]\n",
    "y_val_sample = Y_val[val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec988372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 100 training points:\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6893 - acc: 0.5900 - val_loss: 0.6801 - val_acc: 0.6597\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6723 - acc: 0.6300 - val_loss: 0.6745 - val_acc: 0.6615\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6694 - acc: 0.6500 - val_loss: 0.6686 - val_acc: 0.6615\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6738 - acc: 0.6400 - val_loss: 0.6637 - val_acc: 0.6615\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6721 - acc: 0.6400 - val_loss: 0.6589 - val_acc: 0.6615\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6565 - acc: 0.6400 - val_loss: 0.6540 - val_acc: 0.6615\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6511 - acc: 0.6400 - val_loss: 0.6493 - val_acc: 0.6615\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6349 - acc: 0.6400 - val_loss: 0.6449 - val_acc: 0.6615\n",
      "\n",
      " \n",
      "\n",
      "Training model with 500 training points:\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6970 - acc: 0.4520 - val_loss: 0.6905 - val_acc: 0.6022\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.6923 - acc: 0.5380 - val_loss: 0.6857 - val_acc: 0.6586\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 0.6852 - acc: 0.6220 - val_loss: 0.6816 - val_acc: 0.6615\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.6824 - acc: 0.6400 - val_loss: 0.6779 - val_acc: 0.6615\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 0.6789 - acc: 0.6420 - val_loss: 0.6744 - val_acc: 0.6615\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.6741 - acc: 0.6440 - val_loss: 0.6708 - val_acc: 0.6615\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.6692 - acc: 0.6440 - val_loss: 0.6672 - val_acc: 0.6615\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.6672 - acc: 0.6440 - val_loss: 0.6636 - val_acc: 0.6615\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.6653 - acc: 0.6440 - val_loss: 0.6600 - val_acc: 0.6615\n",
      "\n",
      " \n",
      "\n",
      "Training model with 1000 training points:\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6846 - acc: 0.6430 - val_loss: 0.6796 - val_acc: 0.6615\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.6775 - acc: 0.6400 - val_loss: 0.6736 - val_acc: 0.6615\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6707 - acc: 0.6460 - val_loss: 0.6678 - val_acc: 0.6615\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.6641 - acc: 0.6470 - val_loss: 0.6621 - val_acc: 0.6615\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6602 - acc: 0.6500 - val_loss: 0.6568 - val_acc: 0.6615\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.6530 - acc: 0.6500 - val_loss: 0.6519 - val_acc: 0.6615\n",
      "\n",
      " \n",
      "\n",
      "Training model with 2000 training points:\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6931 - acc: 0.5040 - val_loss: 0.6870 - val_acc: 0.6616\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6869 - acc: 0.6225 - val_loss: 0.6822 - val_acc: 0.6615\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.6829 - acc: 0.6575 - val_loss: 0.6782 - val_acc: 0.6615\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.6787 - acc: 0.6615 - val_loss: 0.6744 - val_acc: 0.6615\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.6769 - acc: 0.6615 - val_loss: 0.6708 - val_acc: 0.6615\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6724 - acc: 0.6610 - val_loss: 0.6672 - val_acc: 0.6615\n",
      "\n",
      " \n",
      "\n",
      "Training model with 5000 training points:\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7013 - acc: 0.4054 - val_loss: 0.6896 - val_acc: 0.5652\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.6924 - acc: 0.5236 - val_loss: 0.6831 - val_acc: 0.6617\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.6850 - acc: 0.6136 - val_loss: 0.6777 - val_acc: 0.6615\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.6783 - acc: 0.6534 - val_loss: 0.6730 - val_acc: 0.6615\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6745 - acc: 0.6616 - val_loss: 0.6687 - val_acc: 0.6615\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.6706 - acc: 0.6644 - val_loss: 0.6647 - val_acc: 0.6615\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.6655 - acc: 0.6634 - val_loss: 0.6607 - val_acc: 0.6615\n",
      "\n",
      " \n",
      "\n",
      "Training model with 7500 training points:\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6845 - acc: 0.6259 - val_loss: 0.6790 - val_acc: 0.6615\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.6775 - acc: 0.6612 - val_loss: 0.6724 - val_acc: 0.6615\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.6710 - acc: 0.6652 - val_loss: 0.6662 - val_acc: 0.6615\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.6665 - acc: 0.6655 - val_loss: 0.6604 - val_acc: 0.6615\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.6593 - acc: 0.6655 - val_loss: 0.6551 - val_acc: 0.6615\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.6551 - acc: 0.6653 - val_loss: 0.6504 - val_acc: 0.6615\n",
      "\n",
      " \n",
      "\n",
      "Training model with 10000 training points:\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6981 - acc: 0.4582 - val_loss: 0.6867 - val_acc: 0.6244\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.6869 - acc: 0.5772 - val_loss: 0.6777 - val_acc: 0.6604\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6759 - acc: 0.6458 - val_loss: 0.6701 - val_acc: 0.6630\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 0.6700 - acc: 0.6596 - val_loss: 0.6636 - val_acc: 0.6615\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.6638 - acc: 0.6619 - val_loss: 0.6578 - val_acc: 0.6615\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.6577 - acc: 0.6625 - val_loss: 0.6525 - val_acc: 0.6615\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6531 - acc: 0.6625 - val_loss: 0.6476 - val_acc: 0.6615\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.6478 - acc: 0.6628 - val_loss: 0.6429 - val_acc: 0.6615\n",
      "\n",
      " \n",
      "\n",
      "Training model with 12500 training points:\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 2s 152ms/step - loss: 0.6816 - acc: 0.6266 - val_loss: 0.6612 - val_acc: 0.6615\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 0.6565 - acc: 0.6644 - val_loss: 0.6418 - val_acc: 0.6615\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.6384 - acc: 0.6643 - val_loss: 0.6249 - val_acc: 0.6615\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.6229 - acc: 0.6640 - val_loss: 0.6097 - val_acc: 0.6615\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.6089 - acc: 0.6647 - val_loss: 0.5966 - val_acc: 0.6647\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.5975 - acc: 0.6653 - val_loss: 0.5863 - val_acc: 0.6722\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.5884 - acc: 0.6686 - val_loss: 0.5804 - val_acc: 0.6737\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.5822 - acc: 0.6752 - val_loss: 0.5760 - val_acc: 0.6752\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.5825 - acc: 0.6742 - val_loss: 0.5709 - val_acc: 0.6792\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.5732 - acc: 0.6788 - val_loss: 0.5662 - val_acc: 0.6803\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 78ms/step - loss: 0.5669 - acc: 0.6829 - val_loss: 0.5622 - val_acc: 0.6822\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.5643 - acc: 0.6806 - val_loss: 0.5622 - val_acc: 0.6829\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.5667 - acc: 0.6813 - val_loss: 0.5585 - val_acc: 0.6849\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.5645 - acc: 0.6848 - val_loss: 0.5569 - val_acc: 0.6862\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.5619 - acc: 0.6860 - val_loss: 0.5551 - val_acc: 0.6859\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.5572 - acc: 0.6876 - val_loss: 0.5565 - val_acc: 0.6863\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.5561 - acc: 0.6926 - val_loss: 0.5522 - val_acc: 0.6879\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.5524 - acc: 0.6943 - val_loss: 0.5505 - val_acc: 0.6890\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.5519 - acc: 0.6919 - val_loss: 0.5486 - val_acc: 0.6899\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.5484 - acc: 0.6932 - val_loss: 0.5494 - val_acc: 0.6911\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.5514 - acc: 0.6904 - val_loss: 0.5493 - val_acc: 0.6922\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.5501 - acc: 0.6996 - val_loss: 0.5461 - val_acc: 0.6943\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.5464 - acc: 0.6945 - val_loss: 0.5455 - val_acc: 0.6958\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.5424 - acc: 0.6966 - val_loss: 0.5445 - val_acc: 0.6966\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.5447 - acc: 0.7030 - val_loss: 0.5436 - val_acc: 0.6973\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.5419 - acc: 0.7011 - val_loss: 0.5451 - val_acc: 0.6993\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.5455 - acc: 0.6964 - val_loss: 0.5422 - val_acc: 0.7002\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.5417 - acc: 0.6999 - val_loss: 0.5403 - val_acc: 0.7025\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.5390 - acc: 0.7038 - val_loss: 0.5391 - val_acc: 0.7041\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.5389 - acc: 0.7001 - val_loss: 0.5385 - val_acc: 0.7041\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.5396 - acc: 0.7072 - val_loss: 0.5390 - val_acc: 0.7041\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.5368 - acc: 0.7069 - val_loss: 0.5376 - val_acc: 0.7036\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.5336 - acc: 0.7063 - val_loss: 0.5353 - val_acc: 0.7045\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.5325 - acc: 0.7070 - val_loss: 0.5338 - val_acc: 0.7060\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.5295 - acc: 0.7106 - val_loss: 0.5352 - val_acc: 0.7063\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.5360 - acc: 0.7108 - val_loss: 0.5312 - val_acc: 0.7092\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.5294 - acc: 0.7077 - val_loss: 0.5307 - val_acc: 0.7093\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.5264 - acc: 0.7156 - val_loss: 0.5304 - val_acc: 0.7103\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.5272 - acc: 0.7122 - val_loss: 0.5288 - val_acc: 0.7118\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.5285 - acc: 0.7066 - val_loss: 0.5285 - val_acc: 0.7132\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.5300 - acc: 0.7121 - val_loss: 0.5291 - val_acc: 0.7150\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.5215 - acc: 0.7163 - val_loss: 0.5263 - val_acc: 0.7165\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.5254 - acc: 0.7136 - val_loss: 0.5260 - val_acc: 0.7151\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.5251 - acc: 0.7182 - val_loss: 0.5245 - val_acc: 0.7182\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.5261 - acc: 0.7131 - val_loss: 0.5273 - val_acc: 0.7160\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.5242 - acc: 0.7128 - val_loss: 0.5215 - val_acc: 0.7196\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.5204 - acc: 0.7191 - val_loss: 0.5211 - val_acc: 0.7186\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.5184 - acc: 0.7241 - val_loss: 0.5220 - val_acc: 0.7195\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.5171 - acc: 0.7206 - val_loss: 0.5206 - val_acc: 0.7213\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.5173 - acc: 0.7212 - val_loss: 0.5183 - val_acc: 0.7212\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.5189 - acc: 0.7196 - val_loss: 0.5176 - val_acc: 0.7205\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.5180 - acc: 0.7194 - val_loss: 0.5165 - val_acc: 0.7238\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.5148 - acc: 0.7222 - val_loss: 0.5152 - val_acc: 0.7240\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 0.5106 - acc: 0.7272 - val_loss: 0.5140 - val_acc: 0.7245\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.5127 - acc: 0.7273 - val_loss: 0.5124 - val_acc: 0.7270\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.5096 - acc: 0.7300 - val_loss: 0.5118 - val_acc: 0.7277\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.5100 - acc: 0.7307 - val_loss: 0.5110 - val_acc: 0.7288\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.5098 - acc: 0.7261 - val_loss: 0.5104 - val_acc: 0.7282\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.5113 - acc: 0.7249 - val_loss: 0.5080 - val_acc: 0.7302\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.5043 - acc: 0.7342 - val_loss: 0.5075 - val_acc: 0.7313\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.5054 - acc: 0.7333 - val_loss: 0.5071 - val_acc: 0.7316\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.5060 - acc: 0.7335 - val_loss: 0.5069 - val_acc: 0.7327\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.5046 - acc: 0.7350 - val_loss: 0.5054 - val_acc: 0.7347\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.5046 - acc: 0.7343 - val_loss: 0.5045 - val_acc: 0.7353\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.5019 - acc: 0.7341 - val_loss: 0.5053 - val_acc: 0.7317\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.5045 - acc: 0.7320 - val_loss: 0.5045 - val_acc: 0.7334\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.5009 - acc: 0.7365 - val_loss: 0.5071 - val_acc: 0.7347\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.5019 - acc: 0.7330 - val_loss: 0.5049 - val_acc: 0.7359\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 0.5032 - acc: 0.7343 - val_loss: 0.5012 - val_acc: 0.7367\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.4980 - acc: 0.7364 - val_loss: 0.5010 - val_acc: 0.7380\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.4970 - acc: 0.7359 - val_loss: 0.4992 - val_acc: 0.7394\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.4965 - acc: 0.7377 - val_loss: 0.4990 - val_acc: 0.7397\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 75ms/step - loss: 0.4966 - acc: 0.7401 - val_loss: 0.4995 - val_acc: 0.7406\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.4957 - acc: 0.7449 - val_loss: 0.4998 - val_acc: 0.7411\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 0.4960 - acc: 0.7395 - val_loss: 0.4976 - val_acc: 0.7408\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.4973 - acc: 0.7377 - val_loss: 0.4965 - val_acc: 0.7402\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 0.4927 - acc: 0.7425 - val_loss: 0.4980 - val_acc: 0.7390\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 0.4898 - acc: 0.7458 - val_loss: 0.4966 - val_acc: 0.7387\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 0.4939 - acc: 0.7398 - val_loss: 0.4966 - val_acc: 0.7405\n",
      "\n",
      " \n",
      "\n",
      "Training model with 15000 training points:\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 2s 156ms/step - loss: 0.7243 - acc: 0.3573 - val_loss: 0.6883 - val_acc: 0.6295\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.6862 - acc: 0.6151 - val_loss: 0.6698 - val_acc: 0.6615\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.6650 - acc: 0.6689 - val_loss: 0.6576 - val_acc: 0.6615\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.6558 - acc: 0.6636 - val_loss: 0.6461 - val_acc: 0.6615\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.6427 - acc: 0.6653 - val_loss: 0.6326 - val_acc: 0.6615\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.6326 - acc: 0.6646 - val_loss: 0.6169 - val_acc: 0.6615\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.6142 - acc: 0.6669 - val_loss: 0.6017 - val_acc: 0.6615\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.6008 - acc: 0.6653 - val_loss: 0.5888 - val_acc: 0.6661\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.5895 - acc: 0.6697 - val_loss: 0.5793 - val_acc: 0.6704\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.5797 - acc: 0.6727 - val_loss: 0.5726 - val_acc: 0.6715\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.5730 - acc: 0.6717 - val_loss: 0.5687 - val_acc: 0.6745\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.5741 - acc: 0.6742 - val_loss: 0.5656 - val_acc: 0.6775\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.5679 - acc: 0.6742 - val_loss: 0.5628 - val_acc: 0.6806\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.5654 - acc: 0.6763 - val_loss: 0.5597 - val_acc: 0.6836\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.5608 - acc: 0.6824 - val_loss: 0.5569 - val_acc: 0.6852\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.5559 - acc: 0.6830 - val_loss: 0.5545 - val_acc: 0.6874\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.5555 - acc: 0.6891 - val_loss: 0.5520 - val_acc: 0.6894\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.5566 - acc: 0.6857 - val_loss: 0.5491 - val_acc: 0.6919\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.5519 - acc: 0.6903 - val_loss: 0.5469 - val_acc: 0.6932\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.5475 - acc: 0.6948 - val_loss: 0.5442 - val_acc: 0.6954\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.5458 - acc: 0.6949 - val_loss: 0.5419 - val_acc: 0.6981\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.5453 - acc: 0.6975 - val_loss: 0.5395 - val_acc: 0.6998\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.5419 - acc: 0.7007 - val_loss: 0.5374 - val_acc: 0.7022\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.5441 - acc: 0.6982 - val_loss: 0.5357 - val_acc: 0.7040\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.5400 - acc: 0.6995 - val_loss: 0.5342 - val_acc: 0.7049\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.5378 - acc: 0.7000 - val_loss: 0.5322 - val_acc: 0.7066\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.5380 - acc: 0.7033 - val_loss: 0.5309 - val_acc: 0.7078\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.5321 - acc: 0.7050 - val_loss: 0.5288 - val_acc: 0.7092\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.5342 - acc: 0.7048 - val_loss: 0.5273 - val_acc: 0.7104\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.5354 - acc: 0.7036 - val_loss: 0.5260 - val_acc: 0.7124\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.5315 - acc: 0.7059 - val_loss: 0.5242 - val_acc: 0.7135\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.5315 - acc: 0.7069 - val_loss: 0.5225 - val_acc: 0.7144\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.5265 - acc: 0.7124 - val_loss: 0.5217 - val_acc: 0.7153\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.5253 - acc: 0.7134 - val_loss: 0.5203 - val_acc: 0.7156\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 103ms/step - loss: 0.5274 - acc: 0.7071 - val_loss: 0.5186 - val_acc: 0.7167\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.5268 - acc: 0.7080 - val_loss: 0.5176 - val_acc: 0.7182\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.5252 - acc: 0.7146 - val_loss: 0.5159 - val_acc: 0.7197\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.5201 - acc: 0.7127 - val_loss: 0.5150 - val_acc: 0.7208\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.5228 - acc: 0.7185 - val_loss: 0.5133 - val_acc: 0.7225\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.5168 - acc: 0.7160 - val_loss: 0.5125 - val_acc: 0.7230\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.5213 - acc: 0.7180 - val_loss: 0.5123 - val_acc: 0.7229\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.5147 - acc: 0.7192 - val_loss: 0.5101 - val_acc: 0.7253\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.5107 - acc: 0.7220 - val_loss: 0.5088 - val_acc: 0.7267\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.5168 - acc: 0.7243 - val_loss: 0.5080 - val_acc: 0.7268\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.5112 - acc: 0.7259 - val_loss: 0.5074 - val_acc: 0.7275\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.5164 - acc: 0.7199 - val_loss: 0.5062 - val_acc: 0.7287\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.5060 - acc: 0.7305 - val_loss: 0.5055 - val_acc: 0.7295\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.5085 - acc: 0.7264 - val_loss: 0.5036 - val_acc: 0.7306\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.5083 - acc: 0.7302 - val_loss: 0.5032 - val_acc: 0.7315\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.5027 - acc: 0.7286 - val_loss: 0.5021 - val_acc: 0.7317\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.5004 - acc: 0.7302 - val_loss: 0.5007 - val_acc: 0.7331\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.4997 - acc: 0.7383 - val_loss: 0.4997 - val_acc: 0.7344\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.5027 - acc: 0.7282 - val_loss: 0.4991 - val_acc: 0.7354\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.4985 - acc: 0.7340 - val_loss: 0.4972 - val_acc: 0.7364\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.4986 - acc: 0.7339 - val_loss: 0.4970 - val_acc: 0.7371\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 87ms/step - loss: 0.4976 - acc: 0.7369 - val_loss: 0.4953 - val_acc: 0.7380\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.5011 - acc: 0.7353 - val_loss: 0.4947 - val_acc: 0.7381\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4979 - acc: 0.7320 - val_loss: 0.4941 - val_acc: 0.7391\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4885 - acc: 0.7456 - val_loss: 0.4927 - val_acc: 0.7410\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.4972 - acc: 0.7344 - val_loss: 0.4919 - val_acc: 0.7409\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4881 - acc: 0.7454 - val_loss: 0.4912 - val_acc: 0.7420\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.4884 - acc: 0.7403 - val_loss: 0.4898 - val_acc: 0.7433\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.4873 - acc: 0.7438 - val_loss: 0.4892 - val_acc: 0.7434\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.4901 - acc: 0.7431 - val_loss: 0.4891 - val_acc: 0.7438\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4834 - acc: 0.7484 - val_loss: 0.4872 - val_acc: 0.7452\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.4870 - acc: 0.7452 - val_loss: 0.4862 - val_acc: 0.7461\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.4820 - acc: 0.7493 - val_loss: 0.4856 - val_acc: 0.7465\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4828 - acc: 0.7454 - val_loss: 0.4847 - val_acc: 0.7469\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4841 - acc: 0.7444 - val_loss: 0.4850 - val_acc: 0.7467\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.4807 - acc: 0.7470 - val_loss: 0.4836 - val_acc: 0.7484\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.4787 - acc: 0.7547 - val_loss: 0.4827 - val_acc: 0.7488\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.4832 - acc: 0.7456 - val_loss: 0.4822 - val_acc: 0.7490\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.4782 - acc: 0.7500 - val_loss: 0.4815 - val_acc: 0.7493\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.4818 - acc: 0.7479 - val_loss: 0.4810 - val_acc: 0.7496\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4802 - acc: 0.7474 - val_loss: 0.4801 - val_acc: 0.7501\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4794 - acc: 0.7495 - val_loss: 0.4795 - val_acc: 0.7510\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.4718 - acc: 0.7571 - val_loss: 0.4788 - val_acc: 0.7512\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.4760 - acc: 0.7519 - val_loss: 0.4776 - val_acc: 0.7526\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.4737 - acc: 0.7537 - val_loss: 0.4781 - val_acc: 0.7516\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 0.4701 - acc: 0.7557 - val_loss: 0.4764 - val_acc: 0.7531\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.4758 - acc: 0.7498 - val_loss: 0.4765 - val_acc: 0.7531\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 0.4684 - acc: 0.7590 - val_loss: 0.4757 - val_acc: 0.7538\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 0.4741 - acc: 0.7529 - val_loss: 0.4751 - val_acc: 0.7541\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 0.4735 - acc: 0.7525 - val_loss: 0.4755 - val_acc: 0.7540\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.4684 - acc: 0.7589 - val_loss: 0.4737 - val_acc: 0.7556\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4681 - acc: 0.7598 - val_loss: 0.4751 - val_acc: 0.7559\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.4638 - acc: 0.7606 - val_loss: 0.4731 - val_acc: 0.7553\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.4691 - acc: 0.7570 - val_loss: 0.4734 - val_acc: 0.7554\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4602 - acc: 0.7616 - val_loss: 0.4712 - val_acc: 0.7570\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.4637 - acc: 0.7612 - val_loss: 0.4708 - val_acc: 0.7578\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4580 - acc: 0.7633 - val_loss: 0.4710 - val_acc: 0.7583\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4632 - acc: 0.7618 - val_loss: 0.4689 - val_acc: 0.7590\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 0.4638 - acc: 0.7626 - val_loss: 0.4697 - val_acc: 0.7586\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.4607 - acc: 0.7638 - val_loss: 0.4680 - val_acc: 0.7584\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.4621 - acc: 0.7595 - val_loss: 0.4686 - val_acc: 0.7597\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4578 - acc: 0.7655 - val_loss: 0.4676 - val_acc: 0.7597\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4572 - acc: 0.7665 - val_loss: 0.4666 - val_acc: 0.7600\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 0.4553 - acc: 0.7697 - val_loss: 0.4670 - val_acc: 0.7605\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4553 - acc: 0.7675 - val_loss: 0.4657 - val_acc: 0.7606\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 0.4544 - acc: 0.7660 - val_loss: 0.4656 - val_acc: 0.7613\n",
      "\n",
      " \n",
      "\n",
      "Training model with 20000 training points:\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 2s 130ms/step - loss: 0.6977 - acc: 0.4682 - val_loss: 0.6655 - val_acc: 0.6615\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.6608 - acc: 0.6624 - val_loss: 0.6448 - val_acc: 0.6615\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.6468 - acc: 0.6622 - val_loss: 0.6263 - val_acc: 0.6615\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.6238 - acc: 0.6618 - val_loss: 0.6067 - val_acc: 0.6648\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.6071 - acc: 0.6640 - val_loss: 0.5915 - val_acc: 0.6672\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.5941 - acc: 0.6653 - val_loss: 0.5820 - val_acc: 0.6668\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.5824 - acc: 0.6677 - val_loss: 0.5745 - val_acc: 0.6736\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.5794 - acc: 0.6750 - val_loss: 0.5671 - val_acc: 0.6806\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.5674 - acc: 0.6819 - val_loss: 0.5621 - val_acc: 0.6857\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.5633 - acc: 0.6870 - val_loss: 0.5585 - val_acc: 0.6885\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.5649 - acc: 0.6840 - val_loss: 0.5546 - val_acc: 0.6918\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.5550 - acc: 0.6914 - val_loss: 0.5514 - val_acc: 0.6941\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.5575 - acc: 0.6908 - val_loss: 0.5480 - val_acc: 0.6970\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.5512 - acc: 0.6965 - val_loss: 0.5453 - val_acc: 0.6988\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.5485 - acc: 0.7001 - val_loss: 0.5426 - val_acc: 0.7012\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.5511 - acc: 0.6981 - val_loss: 0.5404 - val_acc: 0.7032\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.5453 - acc: 0.6955 - val_loss: 0.5386 - val_acc: 0.7059\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 77ms/step - loss: 0.5451 - acc: 0.7019 - val_loss: 0.5370 - val_acc: 0.7071\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.5412 - acc: 0.7044 - val_loss: 0.5352 - val_acc: 0.7084\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.5403 - acc: 0.7062 - val_loss: 0.5329 - val_acc: 0.7100\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.5354 - acc: 0.7071 - val_loss: 0.5312 - val_acc: 0.7111\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.5378 - acc: 0.7098 - val_loss: 0.5292 - val_acc: 0.7127\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.5361 - acc: 0.7074 - val_loss: 0.5279 - val_acc: 0.7142\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 78ms/step - loss: 0.5309 - acc: 0.7130 - val_loss: 0.5257 - val_acc: 0.7158\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.5325 - acc: 0.7117 - val_loss: 0.5238 - val_acc: 0.7180\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.5282 - acc: 0.7175 - val_loss: 0.5222 - val_acc: 0.7193\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.5275 - acc: 0.7153 - val_loss: 0.5206 - val_acc: 0.7203\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.5285 - acc: 0.7167 - val_loss: 0.5191 - val_acc: 0.7214\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.5232 - acc: 0.7190 - val_loss: 0.5176 - val_acc: 0.7229\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.5266 - acc: 0.7158 - val_loss: 0.5156 - val_acc: 0.7232\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.5241 - acc: 0.7186 - val_loss: 0.5146 - val_acc: 0.7249\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.5248 - acc: 0.7182 - val_loss: 0.5123 - val_acc: 0.7257\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.5181 - acc: 0.7225 - val_loss: 0.5115 - val_acc: 0.7273\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.5128 - acc: 0.7270 - val_loss: 0.5091 - val_acc: 0.7281\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.5212 - acc: 0.7228 - val_loss: 0.5080 - val_acc: 0.7295\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.5175 - acc: 0.7226 - val_loss: 0.5065 - val_acc: 0.7310\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.5110 - acc: 0.7275 - val_loss: 0.5049 - val_acc: 0.7318\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.5110 - acc: 0.7276 - val_loss: 0.5035 - val_acc: 0.7333\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.5066 - acc: 0.7337 - val_loss: 0.5020 - val_acc: 0.7339\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.5104 - acc: 0.7282 - val_loss: 0.5001 - val_acc: 0.7347\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.5061 - acc: 0.7327 - val_loss: 0.4992 - val_acc: 0.7357\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.5074 - acc: 0.7300 - val_loss: 0.4977 - val_acc: 0.7362\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.4997 - acc: 0.7372 - val_loss: 0.4967 - val_acc: 0.7377\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.5001 - acc: 0.7358 - val_loss: 0.4948 - val_acc: 0.7391\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.5012 - acc: 0.7362 - val_loss: 0.4935 - val_acc: 0.7398\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.5046 - acc: 0.7342 - val_loss: 0.4925 - val_acc: 0.7401\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.4975 - acc: 0.7345 - val_loss: 0.4912 - val_acc: 0.7413\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.4958 - acc: 0.7405 - val_loss: 0.4903 - val_acc: 0.7422\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.4941 - acc: 0.7372 - val_loss: 0.4884 - val_acc: 0.7440\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.4879 - acc: 0.7441 - val_loss: 0.4871 - val_acc: 0.7447\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.4914 - acc: 0.7364 - val_loss: 0.4858 - val_acc: 0.7456\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.4928 - acc: 0.7386 - val_loss: 0.4856 - val_acc: 0.7459\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.4931 - acc: 0.7427 - val_loss: 0.4841 - val_acc: 0.7460\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.4910 - acc: 0.7428 - val_loss: 0.4833 - val_acc: 0.7462\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.4882 - acc: 0.7421 - val_loss: 0.4827 - val_acc: 0.7479\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.4855 - acc: 0.7483 - val_loss: 0.4805 - val_acc: 0.7474\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.4784 - acc: 0.7496 - val_loss: 0.4816 - val_acc: 0.7486\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.4796 - acc: 0.7486 - val_loss: 0.4793 - val_acc: 0.7494\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.4812 - acc: 0.7504 - val_loss: 0.4789 - val_acc: 0.7494\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.4762 - acc: 0.7540 - val_loss: 0.4772 - val_acc: 0.7496\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.4780 - acc: 0.7504 - val_loss: 0.4783 - val_acc: 0.7509\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.4732 - acc: 0.7526 - val_loss: 0.4753 - val_acc: 0.7508\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.4780 - acc: 0.7513 - val_loss: 0.4758 - val_acc: 0.7524\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.4720 - acc: 0.7552 - val_loss: 0.4722 - val_acc: 0.7530\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.4713 - acc: 0.7536 - val_loss: 0.4721 - val_acc: 0.7534\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.4763 - acc: 0.7511 - val_loss: 0.4727 - val_acc: 0.7544\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.4709 - acc: 0.7565 - val_loss: 0.4697 - val_acc: 0.7544\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.4720 - acc: 0.7553 - val_loss: 0.4708 - val_acc: 0.7546\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 77ms/step - loss: 0.4658 - acc: 0.7553 - val_loss: 0.4693 - val_acc: 0.7557\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.4671 - acc: 0.7593 - val_loss: 0.4682 - val_acc: 0.7564\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 89ms/step - loss: 0.4614 - acc: 0.7636 - val_loss: 0.4680 - val_acc: 0.7575\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.4605 - acc: 0.7656 - val_loss: 0.4673 - val_acc: 0.7577\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.4638 - acc: 0.7615 - val_loss: 0.4660 - val_acc: 0.7580\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.4618 - acc: 0.7612 - val_loss: 0.4643 - val_acc: 0.7586\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.4585 - acc: 0.7609 - val_loss: 0.4634 - val_acc: 0.7595\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.4578 - acc: 0.7622 - val_loss: 0.4637 - val_acc: 0.7597\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.4552 - acc: 0.7672 - val_loss: 0.4631 - val_acc: 0.7605\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.4589 - acc: 0.7624 - val_loss: 0.4630 - val_acc: 0.7609\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.4548 - acc: 0.7646 - val_loss: 0.4623 - val_acc: 0.7622\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 72ms/step - loss: 0.4561 - acc: 0.7628 - val_loss: 0.4614 - val_acc: 0.7623\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.4559 - acc: 0.7652 - val_loss: 0.4621 - val_acc: 0.7621\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.4535 - acc: 0.7658 - val_loss: 0.4623 - val_acc: 0.7624\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.4562 - acc: 0.7612 - val_loss: 0.4607 - val_acc: 0.7625\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.4483 - acc: 0.7695 - val_loss: 0.4603 - val_acc: 0.7633\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.4480 - acc: 0.7698 - val_loss: 0.4585 - val_acc: 0.7644\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.4518 - acc: 0.7619 - val_loss: 0.4573 - val_acc: 0.7643\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.4485 - acc: 0.7693 - val_loss: 0.4576 - val_acc: 0.7642\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.4462 - acc: 0.7730 - val_loss: 0.4581 - val_acc: 0.7658\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.4501 - acc: 0.7683 - val_loss: 0.4551 - val_acc: 0.7669\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.4487 - acc: 0.7654 - val_loss: 0.4552 - val_acc: 0.7665\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.4471 - acc: 0.7707 - val_loss: 0.4552 - val_acc: 0.7674\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.4448 - acc: 0.7687 - val_loss: 0.4530 - val_acc: 0.7675\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.4465 - acc: 0.7687 - val_loss: 0.4544 - val_acc: 0.7688\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.4446 - acc: 0.7737 - val_loss: 0.4535 - val_acc: 0.7690\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.4436 - acc: 0.7707 - val_loss: 0.4530 - val_acc: 0.7697\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.4388 - acc: 0.7736 - val_loss: 0.4519 - val_acc: 0.7700\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.4424 - acc: 0.7721 - val_loss: 0.4502 - val_acc: 0.7709\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.4376 - acc: 0.7771 - val_loss: 0.4499 - val_acc: 0.7718\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.4364 - acc: 0.7771 - val_loss: 0.4495 - val_acc: 0.7714\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 73ms/step - loss: 0.4354 - acc: 0.7743 - val_loss: 0.4499 - val_acc: 0.7722\n",
      "\n",
      " \n",
      "\n",
      "Training model with 30000 training points:\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 2s 85ms/step - loss: 0.6731 - acc: 0.6574 - val_loss: 0.6433 - val_acc: 0.6615\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.6381 - acc: 0.6612 - val_loss: 0.6062 - val_acc: 0.6646\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.6076 - acc: 0.6622 - val_loss: 0.5841 - val_acc: 0.6602\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.5919 - acc: 0.6597 - val_loss: 0.5697 - val_acc: 0.6693\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.5783 - acc: 0.6675 - val_loss: 0.5609 - val_acc: 0.6788\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.5714 - acc: 0.6728 - val_loss: 0.5558 - val_acc: 0.6823\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.5634 - acc: 0.6780 - val_loss: 0.5514 - val_acc: 0.6849\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.5603 - acc: 0.6843 - val_loss: 0.5472 - val_acc: 0.6891\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.5590 - acc: 0.6801 - val_loss: 0.5427 - val_acc: 0.6952\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.5501 - acc: 0.6893 - val_loss: 0.5388 - val_acc: 0.6991\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.5502 - acc: 0.6896 - val_loss: 0.5354 - val_acc: 0.7018\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.5460 - acc: 0.6942 - val_loss: 0.5326 - val_acc: 0.7069\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.5461 - acc: 0.6917 - val_loss: 0.5296 - val_acc: 0.7096\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.5433 - acc: 0.6957 - val_loss: 0.5268 - val_acc: 0.7123\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.5423 - acc: 0.6984 - val_loss: 0.5233 - val_acc: 0.7148\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.5377 - acc: 0.7069 - val_loss: 0.5202 - val_acc: 0.7176\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.5322 - acc: 0.7079 - val_loss: 0.5172 - val_acc: 0.7205\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.5313 - acc: 0.7111 - val_loss: 0.5150 - val_acc: 0.7225\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.5280 - acc: 0.7083 - val_loss: 0.5118 - val_acc: 0.7244\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.5258 - acc: 0.7131 - val_loss: 0.5092 - val_acc: 0.7280\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.5228 - acc: 0.7158 - val_loss: 0.5062 - val_acc: 0.7291\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.5190 - acc: 0.7223 - val_loss: 0.5026 - val_acc: 0.7332\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.5152 - acc: 0.7238 - val_loss: 0.4997 - val_acc: 0.7357\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.5125 - acc: 0.7221 - val_loss: 0.4974 - val_acc: 0.7365\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.5137 - acc: 0.7254 - val_loss: 0.4949 - val_acc: 0.7386\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.5066 - acc: 0.7283 - val_loss: 0.4919 - val_acc: 0.7414\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.5064 - acc: 0.7280 - val_loss: 0.4906 - val_acc: 0.7415\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.5029 - acc: 0.7343 - val_loss: 0.4877 - val_acc: 0.7441\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.5027 - acc: 0.7315 - val_loss: 0.4857 - val_acc: 0.7463\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.5003 - acc: 0.7316 - val_loss: 0.4842 - val_acc: 0.7471\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.4937 - acc: 0.7372 - val_loss: 0.4828 - val_acc: 0.7479\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.4965 - acc: 0.7368 - val_loss: 0.4804 - val_acc: 0.7492\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.4952 - acc: 0.7374 - val_loss: 0.4784 - val_acc: 0.7507\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.4940 - acc: 0.7391 - val_loss: 0.4770 - val_acc: 0.7520\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.4898 - acc: 0.7432 - val_loss: 0.4756 - val_acc: 0.7520\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.4857 - acc: 0.7433 - val_loss: 0.4736 - val_acc: 0.7534\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.4886 - acc: 0.7429 - val_loss: 0.4730 - val_acc: 0.7537\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.4865 - acc: 0.7455 - val_loss: 0.4715 - val_acc: 0.7536\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.4823 - acc: 0.7451 - val_loss: 0.4688 - val_acc: 0.7561\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.4837 - acc: 0.7499 - val_loss: 0.4676 - val_acc: 0.7574\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.4756 - acc: 0.7539 - val_loss: 0.4660 - val_acc: 0.7579\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 56ms/step - loss: 0.4818 - acc: 0.7471 - val_loss: 0.4651 - val_acc: 0.7587\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.4744 - acc: 0.7502 - val_loss: 0.4628 - val_acc: 0.7594\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.4749 - acc: 0.7504 - val_loss: 0.4615 - val_acc: 0.7616\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.4725 - acc: 0.7556 - val_loss: 0.4606 - val_acc: 0.7612\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.4712 - acc: 0.7568 - val_loss: 0.4596 - val_acc: 0.7620\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.4667 - acc: 0.7587 - val_loss: 0.4582 - val_acc: 0.7637\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.4667 - acc: 0.7561 - val_loss: 0.4591 - val_acc: 0.7614\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.4647 - acc: 0.7580 - val_loss: 0.4568 - val_acc: 0.7637\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.4663 - acc: 0.7593 - val_loss: 0.4549 - val_acc: 0.7663\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.4627 - acc: 0.7577 - val_loss: 0.4551 - val_acc: 0.7659\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.4648 - acc: 0.7605 - val_loss: 0.4541 - val_acc: 0.7670\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.4654 - acc: 0.7620 - val_loss: 0.4523 - val_acc: 0.7683\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.4626 - acc: 0.7612 - val_loss: 0.4507 - val_acc: 0.7669\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.4563 - acc: 0.7660 - val_loss: 0.4497 - val_acc: 0.7696\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.4562 - acc: 0.7622 - val_loss: 0.4487 - val_acc: 0.7695\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.4544 - acc: 0.7688 - val_loss: 0.4481 - val_acc: 0.7701\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.4572 - acc: 0.7655 - val_loss: 0.4463 - val_acc: 0.7714\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.4553 - acc: 0.7642 - val_loss: 0.4456 - val_acc: 0.7721\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.4475 - acc: 0.7687 - val_loss: 0.4456 - val_acc: 0.7722\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.4482 - acc: 0.7715 - val_loss: 0.4437 - val_acc: 0.7725\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.4491 - acc: 0.7711 - val_loss: 0.4427 - val_acc: 0.7742\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.4524 - acc: 0.7666 - val_loss: 0.4433 - val_acc: 0.7745\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.4503 - acc: 0.7669 - val_loss: 0.4407 - val_acc: 0.7744\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.4503 - acc: 0.7672 - val_loss: 0.4413 - val_acc: 0.7742\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.4486 - acc: 0.7671 - val_loss: 0.4404 - val_acc: 0.7757\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.4453 - acc: 0.7706 - val_loss: 0.4396 - val_acc: 0.7769\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.4451 - acc: 0.7710 - val_loss: 0.4389 - val_acc: 0.7780\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.4434 - acc: 0.7745 - val_loss: 0.4371 - val_acc: 0.7782\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.4441 - acc: 0.7726 - val_loss: 0.4362 - val_acc: 0.7782\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.4427 - acc: 0.7742 - val_loss: 0.4347 - val_acc: 0.7792\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.4387 - acc: 0.7744 - val_loss: 0.4339 - val_acc: 0.7811\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.4376 - acc: 0.7761 - val_loss: 0.4321 - val_acc: 0.7819\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.4380 - acc: 0.7765 - val_loss: 0.4323 - val_acc: 0.7818\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.4363 - acc: 0.7768 - val_loss: 0.4305 - val_acc: 0.7835\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.4344 - acc: 0.7808 - val_loss: 0.4309 - val_acc: 0.7832\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.4387 - acc: 0.7763 - val_loss: 0.4285 - val_acc: 0.7841\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.4330 - acc: 0.7815 - val_loss: 0.4291 - val_acc: 0.7835\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.4379 - acc: 0.7772 - val_loss: 0.4279 - val_acc: 0.7847\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.4310 - acc: 0.7826 - val_loss: 0.4280 - val_acc: 0.7840\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.4302 - acc: 0.7830 - val_loss: 0.4255 - val_acc: 0.7862\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.4276 - acc: 0.7844 - val_loss: 0.4256 - val_acc: 0.7855\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.4291 - acc: 0.7827 - val_loss: 0.4245 - val_acc: 0.7875\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.4299 - acc: 0.7856 - val_loss: 0.4228 - val_acc: 0.7883\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.4203 - acc: 0.7904 - val_loss: 0.4235 - val_acc: 0.7877\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.4236 - acc: 0.7902 - val_loss: 0.4224 - val_acc: 0.7881\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.4250 - acc: 0.7882 - val_loss: 0.4216 - val_acc: 0.7894\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.4254 - acc: 0.7881 - val_loss: 0.4207 - val_acc: 0.7906\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.4250 - acc: 0.7856 - val_loss: 0.4195 - val_acc: 0.7912\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.4258 - acc: 0.7859 - val_loss: 0.4186 - val_acc: 0.7910\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.4203 - acc: 0.7899 - val_loss: 0.4183 - val_acc: 0.7918\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.4238 - acc: 0.7868 - val_loss: 0.4174 - val_acc: 0.7922\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.4151 - acc: 0.7923 - val_loss: 0.4205 - val_acc: 0.7898\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.4175 - acc: 0.7936 - val_loss: 0.4184 - val_acc: 0.7908\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.4167 - acc: 0.7905 - val_loss: 0.4151 - val_acc: 0.7940\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.4147 - acc: 0.7922 - val_loss: 0.4140 - val_acc: 0.7960\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.4147 - acc: 0.7940 - val_loss: 0.4133 - val_acc: 0.7955\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.4148 - acc: 0.7925 - val_loss: 0.4126 - val_acc: 0.7961\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.4138 - acc: 0.7915 - val_loss: 0.4120 - val_acc: 0.7962\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 52ms/step - loss: 0.4165 - acc: 0.7923 - val_loss: 0.4119 - val_acc: 0.7968\n",
      "\n",
      " \n",
      "\n",
      "Training model with 50000 training points:\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 2s 70ms/step - loss: 0.6742 - acc: 0.6144 - val_loss: 0.6214 - val_acc: 0.6615\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.6207 - acc: 0.6587 - val_loss: 0.5828 - val_acc: 0.6651\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.5868 - acc: 0.6673 - val_loss: 0.5671 - val_acc: 0.6742\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 47ms/step - loss: 0.5725 - acc: 0.6709 - val_loss: 0.5568 - val_acc: 0.6822\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.5659 - acc: 0.6771 - val_loss: 0.5495 - val_acc: 0.6857\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.5607 - acc: 0.6801 - val_loss: 0.5433 - val_acc: 0.6907\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.5521 - acc: 0.6901 - val_loss: 0.5379 - val_acc: 0.6970\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.5488 - acc: 0.6932 - val_loss: 0.5325 - val_acc: 0.7030\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.5450 - acc: 0.6937 - val_loss: 0.5272 - val_acc: 0.7087\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.5396 - acc: 0.7007 - val_loss: 0.5200 - val_acc: 0.7154\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.5338 - acc: 0.7038 - val_loss: 0.5148 - val_acc: 0.7199\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.5320 - acc: 0.7076 - val_loss: 0.5095 - val_acc: 0.7255\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.5223 - acc: 0.7153 - val_loss: 0.5041 - val_acc: 0.7295\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.5254 - acc: 0.7138 - val_loss: 0.5010 - val_acc: 0.7328\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.5169 - acc: 0.7176 - val_loss: 0.4946 - val_acc: 0.7372\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.5108 - acc: 0.7263 - val_loss: 0.4896 - val_acc: 0.7418\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.5118 - acc: 0.7238 - val_loss: 0.4867 - val_acc: 0.7437\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.4994 - acc: 0.7355 - val_loss: 0.4835 - val_acc: 0.7473\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.4982 - acc: 0.7321 - val_loss: 0.4817 - val_acc: 0.7474\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.4968 - acc: 0.7353 - val_loss: 0.4779 - val_acc: 0.7505\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.4937 - acc: 0.7375 - val_loss: 0.4763 - val_acc: 0.7505\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.4881 - acc: 0.7416 - val_loss: 0.4726 - val_acc: 0.7534\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.4891 - acc: 0.7372 - val_loss: 0.4699 - val_acc: 0.7554\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4827 - acc: 0.7441 - val_loss: 0.4678 - val_acc: 0.7569\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.4821 - acc: 0.7447 - val_loss: 0.4657 - val_acc: 0.7587\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.4806 - acc: 0.7477 - val_loss: 0.4642 - val_acc: 0.7585\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4746 - acc: 0.7492 - val_loss: 0.4617 - val_acc: 0.7603\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4745 - acc: 0.7513 - val_loss: 0.4609 - val_acc: 0.7604\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4744 - acc: 0.7497 - val_loss: 0.4585 - val_acc: 0.7625\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4714 - acc: 0.7520 - val_loss: 0.4563 - val_acc: 0.7639\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.4669 - acc: 0.7567 - val_loss: 0.4554 - val_acc: 0.7643\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.4679 - acc: 0.7521 - val_loss: 0.4528 - val_acc: 0.7649\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.4658 - acc: 0.7552 - val_loss: 0.4518 - val_acc: 0.7659\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.4600 - acc: 0.7591 - val_loss: 0.4492 - val_acc: 0.7673\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.4577 - acc: 0.7601 - val_loss: 0.4490 - val_acc: 0.7674\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.4611 - acc: 0.7610 - val_loss: 0.4471 - val_acc: 0.7688\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.4563 - acc: 0.7606 - val_loss: 0.4460 - val_acc: 0.7693\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.4562 - acc: 0.7607 - val_loss: 0.4438 - val_acc: 0.7704\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4563 - acc: 0.7615 - val_loss: 0.4425 - val_acc: 0.7706\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4529 - acc: 0.7636 - val_loss: 0.4435 - val_acc: 0.7706\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4527 - acc: 0.7633 - val_loss: 0.4401 - val_acc: 0.7729\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4530 - acc: 0.7648 - val_loss: 0.4387 - val_acc: 0.7738\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.4499 - acc: 0.7651 - val_loss: 0.4380 - val_acc: 0.7740\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4510 - acc: 0.7652 - val_loss: 0.4369 - val_acc: 0.7747\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4461 - acc: 0.7690 - val_loss: 0.4357 - val_acc: 0.7771\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4476 - acc: 0.7679 - val_loss: 0.4350 - val_acc: 0.7773\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4436 - acc: 0.7708 - val_loss: 0.4341 - val_acc: 0.7774\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.4419 - acc: 0.7732 - val_loss: 0.4320 - val_acc: 0.7796\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.4415 - acc: 0.7718 - val_loss: 0.4322 - val_acc: 0.7800\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.4412 - acc: 0.7702 - val_loss: 0.4299 - val_acc: 0.7815\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4359 - acc: 0.7745 - val_loss: 0.4287 - val_acc: 0.7829\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4388 - acc: 0.7731 - val_loss: 0.4278 - val_acc: 0.7834\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.4324 - acc: 0.7769 - val_loss: 0.4253 - val_acc: 0.7849\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.4341 - acc: 0.7787 - val_loss: 0.4245 - val_acc: 0.7852\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.4359 - acc: 0.7761 - val_loss: 0.4230 - val_acc: 0.7866\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.4331 - acc: 0.7773 - val_loss: 0.4220 - val_acc: 0.7874\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.4325 - acc: 0.7784 - val_loss: 0.4222 - val_acc: 0.7875\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.4287 - acc: 0.7804 - val_loss: 0.4199 - val_acc: 0.7889\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4295 - acc: 0.7835 - val_loss: 0.4174 - val_acc: 0.7903\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4303 - acc: 0.7793 - val_loss: 0.4184 - val_acc: 0.7904\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.4294 - acc: 0.7815 - val_loss: 0.4149 - val_acc: 0.7937\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4215 - acc: 0.7869 - val_loss: 0.4130 - val_acc: 0.7953\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4195 - acc: 0.7880 - val_loss: 0.4123 - val_acc: 0.7954\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4200 - acc: 0.7872 - val_loss: 0.4119 - val_acc: 0.7950\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.4201 - acc: 0.7899 - val_loss: 0.4097 - val_acc: 0.7976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4182 - acc: 0.7906 - val_loss: 0.4077 - val_acc: 0.7983\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4155 - acc: 0.7938 - val_loss: 0.4059 - val_acc: 0.7998\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.4145 - acc: 0.7943 - val_loss: 0.4055 - val_acc: 0.8008\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4148 - acc: 0.7920 - val_loss: 0.4037 - val_acc: 0.8017\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4154 - acc: 0.7911 - val_loss: 0.4042 - val_acc: 0.8007\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.4118 - acc: 0.7949 - val_loss: 0.4025 - val_acc: 0.8026\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4129 - acc: 0.7938 - val_loss: 0.3999 - val_acc: 0.8041\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.4091 - acc: 0.7969 - val_loss: 0.3987 - val_acc: 0.8052\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4060 - acc: 0.7980 - val_loss: 0.3971 - val_acc: 0.8066\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.4073 - acc: 0.7987 - val_loss: 0.3968 - val_acc: 0.8062\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4048 - acc: 0.7981 - val_loss: 0.3959 - val_acc: 0.8077\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4030 - acc: 0.8003 - val_loss: 0.3944 - val_acc: 0.8081\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4034 - acc: 0.8003 - val_loss: 0.3933 - val_acc: 0.8094\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.4003 - acc: 0.8027 - val_loss: 0.3921 - val_acc: 0.8092\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.3989 - acc: 0.8038 - val_loss: 0.3932 - val_acc: 0.8086\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.3993 - acc: 0.8034 - val_loss: 0.3903 - val_acc: 0.8106\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.4000 - acc: 0.8027 - val_loss: 0.3930 - val_acc: 0.8095\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.3959 - acc: 0.8051 - val_loss: 0.3919 - val_acc: 0.8102\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.3974 - acc: 0.8036 - val_loss: 0.3890 - val_acc: 0.8118\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.4012 - acc: 0.8023 - val_loss: 0.3881 - val_acc: 0.8118\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.3918 - acc: 0.8066 - val_loss: 0.3898 - val_acc: 0.8100\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.3963 - acc: 0.8062 - val_loss: 0.3883 - val_acc: 0.8109\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.3938 - acc: 0.8101 - val_loss: 0.3862 - val_acc: 0.8139\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.3957 - acc: 0.8061 - val_loss: 0.3862 - val_acc: 0.8123\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.3929 - acc: 0.8093 - val_loss: 0.3849 - val_acc: 0.8135\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.3919 - acc: 0.8088 - val_loss: 0.3850 - val_acc: 0.8137\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.3937 - acc: 0.8071 - val_loss: 0.3849 - val_acc: 0.8139\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.3920 - acc: 0.8074 - val_loss: 0.3848 - val_acc: 0.8139\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.3914 - acc: 0.8074 - val_loss: 0.3842 - val_acc: 0.8143\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.3920 - acc: 0.8083 - val_loss: 0.3821 - val_acc: 0.8155\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.3891 - acc: 0.8104 - val_loss: 0.3819 - val_acc: 0.8157\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.3917 - acc: 0.8071 - val_loss: 0.3831 - val_acc: 0.8151\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.3858 - acc: 0.8101 - val_loss: 0.3829 - val_acc: 0.8138\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.3856 - acc: 0.8116 - val_loss: 0.3811 - val_acc: 0.8158\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.3877 - acc: 0.8082 - val_loss: 0.3811 - val_acc: 0.8155\n",
      "\n",
      " \n",
      "\n",
      "Training model with 100000 training points:\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 2s 52ms/step - loss: 0.6699 - acc: 0.5979 - val_loss: 0.5961 - val_acc: 0.6700\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.5915 - acc: 0.6692 - val_loss: 0.5579 - val_acc: 0.6850\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.5664 - acc: 0.6809 - val_loss: 0.5425 - val_acc: 0.7004\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.5530 - acc: 0.6933 - val_loss: 0.5311 - val_acc: 0.7093\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.5416 - acc: 0.7023 - val_loss: 0.5219 - val_acc: 0.7158\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 0.5349 - acc: 0.7086 - val_loss: 0.5128 - val_acc: 0.7238\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.5279 - acc: 0.7141 - val_loss: 0.5049 - val_acc: 0.7308\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.5176 - acc: 0.7202 - val_loss: 0.4982 - val_acc: 0.7378\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.5148 - acc: 0.7243 - val_loss: 0.4920 - val_acc: 0.7419\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.5053 - acc: 0.7316 - val_loss: 0.4860 - val_acc: 0.7469\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.5010 - acc: 0.7333 - val_loss: 0.4818 - val_acc: 0.7492\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.4966 - acc: 0.7350 - val_loss: 0.4765 - val_acc: 0.7539\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.4903 - acc: 0.7417 - val_loss: 0.4717 - val_acc: 0.7563\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.4881 - acc: 0.7452 - val_loss: 0.4682 - val_acc: 0.7585\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.4840 - acc: 0.7458 - val_loss: 0.4646 - val_acc: 0.7609\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.4788 - acc: 0.7475 - val_loss: 0.4593 - val_acc: 0.7640\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.4754 - acc: 0.7497 - val_loss: 0.4555 - val_acc: 0.7651\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.4702 - acc: 0.7527 - val_loss: 0.4533 - val_acc: 0.7658\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.4687 - acc: 0.7536 - val_loss: 0.4497 - val_acc: 0.7688\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.4629 - acc: 0.7592 - val_loss: 0.4471 - val_acc: 0.7700\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.4612 - acc: 0.7598 - val_loss: 0.4448 - val_acc: 0.7718\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.4591 - acc: 0.7610 - val_loss: 0.4413 - val_acc: 0.7739\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.4542 - acc: 0.7652 - val_loss: 0.4386 - val_acc: 0.7756\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.4545 - acc: 0.7643 - val_loss: 0.4368 - val_acc: 0.7777\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.4501 - acc: 0.7685 - val_loss: 0.4341 - val_acc: 0.7797\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.4511 - acc: 0.7656 - val_loss: 0.4295 - val_acc: 0.7823\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 40ms/step - loss: 0.4451 - acc: 0.7694 - val_loss: 0.4282 - val_acc: 0.7827\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.4426 - acc: 0.7727 - val_loss: 0.4229 - val_acc: 0.7870\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.4390 - acc: 0.7759 - val_loss: 0.4203 - val_acc: 0.7905\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.4357 - acc: 0.7794 - val_loss: 0.4161 - val_acc: 0.7926\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.4333 - acc: 0.7788 - val_loss: 0.4142 - val_acc: 0.7947\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.4276 - acc: 0.7846 - val_loss: 0.4100 - val_acc: 0.7969\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.4279 - acc: 0.7833 - val_loss: 0.4069 - val_acc: 0.8001\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.4230 - acc: 0.7856 - val_loss: 0.4049 - val_acc: 0.8001\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.4204 - acc: 0.7887 - val_loss: 0.4014 - val_acc: 0.8030\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.4177 - acc: 0.7899 - val_loss: 0.3987 - val_acc: 0.8047\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.4150 - acc: 0.7915 - val_loss: 0.3950 - val_acc: 0.8064\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.4125 - acc: 0.7943 - val_loss: 0.3935 - val_acc: 0.8075\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.4105 - acc: 0.7956 - val_loss: 0.3919 - val_acc: 0.8092\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.4062 - acc: 0.7991 - val_loss: 0.3949 - val_acc: 0.8065\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.4086 - acc: 0.7962 - val_loss: 0.3873 - val_acc: 0.8108\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.4011 - acc: 0.8025 - val_loss: 0.3881 - val_acc: 0.8113\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.4042 - acc: 0.7994 - val_loss: 0.3848 - val_acc: 0.8126\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.4013 - acc: 0.8005 - val_loss: 0.3839 - val_acc: 0.8127\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.3997 - acc: 0.8027 - val_loss: 0.3849 - val_acc: 0.8131\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.3967 - acc: 0.8050 - val_loss: 0.3824 - val_acc: 0.8138\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.3990 - acc: 0.8010 - val_loss: 0.3806 - val_acc: 0.8143\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.3972 - acc: 0.8039 - val_loss: 0.3811 - val_acc: 0.8145\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.3955 - acc: 0.8036 - val_loss: 0.3794 - val_acc: 0.8142\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.3939 - acc: 0.8057 - val_loss: 0.3790 - val_acc: 0.8162\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.3914 - acc: 0.8062 - val_loss: 0.3762 - val_acc: 0.8170\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.3900 - acc: 0.8081 - val_loss: 0.3755 - val_acc: 0.8171\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.3913 - acc: 0.8065 - val_loss: 0.3755 - val_acc: 0.8176\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.3871 - acc: 0.8106 - val_loss: 0.3755 - val_acc: 0.8175\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.3840 - acc: 0.8127 - val_loss: 0.3751 - val_acc: 0.8171\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.3885 - acc: 0.8093 - val_loss: 0.3746 - val_acc: 0.8184\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.3858 - acc: 0.8123 - val_loss: 0.3735 - val_acc: 0.8193\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.3862 - acc: 0.8103 - val_loss: 0.3731 - val_acc: 0.8181\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.3825 - acc: 0.8134 - val_loss: 0.3719 - val_acc: 0.8189\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.3852 - acc: 0.8102 - val_loss: 0.3712 - val_acc: 0.8194\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.3831 - acc: 0.8110 - val_loss: 0.3720 - val_acc: 0.8189\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.3815 - acc: 0.8131 - val_loss: 0.3701 - val_acc: 0.8206\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.3822 - acc: 0.8136 - val_loss: 0.3707 - val_acc: 0.8207\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.3840 - acc: 0.8120 - val_loss: 0.3691 - val_acc: 0.8204\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.3797 - acc: 0.8138 - val_loss: 0.3695 - val_acc: 0.8209\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.3781 - acc: 0.8148 - val_loss: 0.3697 - val_acc: 0.8205\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.3793 - acc: 0.8146 - val_loss: 0.3684 - val_acc: 0.8213\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 1s 39ms/step - loss: 0.3787 - acc: 0.8157 - val_loss: 0.3682 - val_acc: 0.8218\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.3764 - acc: 0.8175 - val_loss: 0.3673 - val_acc: 0.8224\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.3773 - acc: 0.8161 - val_loss: 0.3673 - val_acc: 0.8224\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.3779 - acc: 0.8154 - val_loss: 0.3667 - val_acc: 0.8224\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.3776 - acc: 0.8147 - val_loss: 0.3687 - val_acc: 0.8220\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.3782 - acc: 0.8141 - val_loss: 0.3660 - val_acc: 0.8231\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 1s 42ms/step - loss: 0.3769 - acc: 0.8180 - val_loss: 0.3687 - val_acc: 0.8211\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.3767 - acc: 0.8168 - val_loss: 0.3664 - val_acc: 0.8225\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.3740 - acc: 0.8193 - val_loss: 0.3667 - val_acc: 0.8222\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 1s 40ms/step - loss: 0.3745 - acc: 0.8164 - val_loss: 0.3652 - val_acc: 0.8230\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 1s 41ms/step - loss: 0.3743 - acc: 0.8161 - val_loss: 0.3648 - val_acc: 0.8230\n",
      "\n",
      " \n",
      "\n",
      "Training model with 200000 training points:\n",
      "Epoch 1/100\n",
      "49/49 [==============================] - 4s 44ms/step - loss: 0.6520 - acc: 0.6177 - val_loss: 0.5617 - val_acc: 0.6832\n",
      "Epoch 2/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.5649 - acc: 0.6795 - val_loss: 0.5354 - val_acc: 0.7022\n",
      "Epoch 3/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.5430 - acc: 0.6971 - val_loss: 0.5172 - val_acc: 0.7181\n",
      "Epoch 4/100\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.5293 - acc: 0.7102 - val_loss: 0.5022 - val_acc: 0.7341\n",
      "Epoch 5/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.5136 - acc: 0.7244 - val_loss: 0.4875 - val_acc: 0.7435\n",
      "Epoch 6/100\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.5015 - acc: 0.7310 - val_loss: 0.4751 - val_acc: 0.7517\n",
      "Epoch 7/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.4903 - acc: 0.7392 - val_loss: 0.4641 - val_acc: 0.7585\n",
      "Epoch 8/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.4802 - acc: 0.7459 - val_loss: 0.4551 - val_acc: 0.7643\n",
      "Epoch 9/100\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.4694 - acc: 0.7528 - val_loss: 0.4500 - val_acc: 0.7665\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 37ms/step - loss: 0.4642 - acc: 0.7575 - val_loss: 0.4436 - val_acc: 0.7707\n",
      "Epoch 11/100\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.4553 - acc: 0.7634 - val_loss: 0.4352 - val_acc: 0.7784\n",
      "Epoch 12/100\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.4508 - acc: 0.7665 - val_loss: 0.4287 - val_acc: 0.7833\n",
      "Epoch 13/100\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.4437 - acc: 0.7703 - val_loss: 0.4217 - val_acc: 0.7881\n",
      "Epoch 14/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.4375 - acc: 0.7762 - val_loss: 0.4154 - val_acc: 0.7945\n",
      "Epoch 15/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.4329 - acc: 0.7813 - val_loss: 0.4083 - val_acc: 0.7981\n",
      "Epoch 16/100\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.4235 - acc: 0.7872 - val_loss: 0.4023 - val_acc: 0.8031\n",
      "Epoch 17/100\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.4192 - acc: 0.7897 - val_loss: 0.3969 - val_acc: 0.8077\n",
      "Epoch 18/100\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.4126 - acc: 0.7960 - val_loss: 0.3950 - val_acc: 0.8080\n",
      "Epoch 19/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.4070 - acc: 0.7982 - val_loss: 0.3885 - val_acc: 0.8120\n",
      "Epoch 20/100\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.4050 - acc: 0.8000 - val_loss: 0.3870 - val_acc: 0.8131\n",
      "Epoch 21/100\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.4004 - acc: 0.8030 - val_loss: 0.3844 - val_acc: 0.8142\n",
      "Epoch 22/100\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.3999 - acc: 0.8027 - val_loss: 0.3807 - val_acc: 0.8160\n",
      "Epoch 23/100\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.3976 - acc: 0.8051 - val_loss: 0.3795 - val_acc: 0.8171\n",
      "Epoch 24/100\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.3945 - acc: 0.8070 - val_loss: 0.3774 - val_acc: 0.8180\n",
      "Epoch 25/100\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3938 - acc: 0.8075 - val_loss: 0.3746 - val_acc: 0.8201\n",
      "Epoch 26/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3908 - acc: 0.8093 - val_loss: 0.3749 - val_acc: 0.8197\n",
      "Epoch 27/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3893 - acc: 0.8093 - val_loss: 0.3726 - val_acc: 0.8218\n",
      "Epoch 28/100\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.3874 - acc: 0.8112 - val_loss: 0.3717 - val_acc: 0.8201\n",
      "Epoch 29/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3864 - acc: 0.8108 - val_loss: 0.3711 - val_acc: 0.8213\n",
      "Epoch 30/100\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.3833 - acc: 0.8127 - val_loss: 0.3701 - val_acc: 0.8213\n",
      "Epoch 31/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3836 - acc: 0.8131 - val_loss: 0.3693 - val_acc: 0.8221\n",
      "Epoch 32/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3830 - acc: 0.8137 - val_loss: 0.3687 - val_acc: 0.8229\n",
      "Epoch 33/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3835 - acc: 0.8121 - val_loss: 0.3684 - val_acc: 0.8224\n",
      "Epoch 34/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3802 - acc: 0.8153 - val_loss: 0.3678 - val_acc: 0.8220\n",
      "Epoch 35/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3812 - acc: 0.8131 - val_loss: 0.3654 - val_acc: 0.8241\n",
      "Epoch 36/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3798 - acc: 0.8150 - val_loss: 0.3650 - val_acc: 0.8254\n",
      "Epoch 37/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3804 - acc: 0.8149 - val_loss: 0.3655 - val_acc: 0.8234\n",
      "Epoch 38/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3786 - acc: 0.8159 - val_loss: 0.3634 - val_acc: 0.8257\n",
      "Epoch 39/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3778 - acc: 0.8168 - val_loss: 0.3638 - val_acc: 0.8250\n",
      "Epoch 40/100\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.3768 - acc: 0.8171 - val_loss: 0.3632 - val_acc: 0.8257\n",
      "Epoch 41/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3748 - acc: 0.8174 - val_loss: 0.3627 - val_acc: 0.8254\n",
      "Epoch 42/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3743 - acc: 0.8185 - val_loss: 0.3625 - val_acc: 0.8260\n",
      "Epoch 43/100\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.3767 - acc: 0.8166 - val_loss: 0.3629 - val_acc: 0.8256\n",
      "Epoch 44/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3743 - acc: 0.8165 - val_loss: 0.3614 - val_acc: 0.8251\n",
      "Epoch 45/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3718 - acc: 0.8182 - val_loss: 0.3603 - val_acc: 0.8266\n",
      "Epoch 46/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3726 - acc: 0.8183 - val_loss: 0.3606 - val_acc: 0.8269\n",
      "Epoch 47/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3704 - acc: 0.8210 - val_loss: 0.3594 - val_acc: 0.8271\n",
      "Epoch 48/100\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.3705 - acc: 0.8203 - val_loss: 0.3594 - val_acc: 0.8270\n",
      "Epoch 49/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3710 - acc: 0.8206 - val_loss: 0.3589 - val_acc: 0.8277\n",
      "Epoch 50/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3697 - acc: 0.8208 - val_loss: 0.3582 - val_acc: 0.8280\n",
      "Epoch 51/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3694 - acc: 0.8214 - val_loss: 0.3589 - val_acc: 0.8270\n",
      "Epoch 52/100\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.3687 - acc: 0.8222 - val_loss: 0.3584 - val_acc: 0.8275\n",
      "Epoch 53/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3684 - acc: 0.8214 - val_loss: 0.3588 - val_acc: 0.8270\n",
      "Epoch 54/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3668 - acc: 0.8223 - val_loss: 0.3572 - val_acc: 0.8286\n",
      "Epoch 55/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3675 - acc: 0.8219 - val_loss: 0.3571 - val_acc: 0.8284\n",
      "Epoch 56/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3659 - acc: 0.8220 - val_loss: 0.3579 - val_acc: 0.8282\n",
      "Epoch 57/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3679 - acc: 0.8224 - val_loss: 0.3565 - val_acc: 0.8294\n",
      "Epoch 58/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3655 - acc: 0.8233 - val_loss: 0.3570 - val_acc: 0.8281\n",
      "Epoch 59/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3643 - acc: 0.8232 - val_loss: 0.3550 - val_acc: 0.8293\n",
      "Epoch 60/100\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.3658 - acc: 0.8227 - val_loss: 0.3551 - val_acc: 0.8293\n",
      "Epoch 61/100\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.3642 - acc: 0.8247 - val_loss: 0.3542 - val_acc: 0.8302\n",
      "Epoch 62/100\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.3645 - acc: 0.8237 - val_loss: 0.3547 - val_acc: 0.8308\n",
      "Epoch 63/100\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.3669 - acc: 0.8228 - val_loss: 0.3548 - val_acc: 0.8307\n",
      "Epoch 64/100\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.3644 - acc: 0.8228 - val_loss: 0.3541 - val_acc: 0.8300\n",
      "Epoch 65/100\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.3631 - acc: 0.8240 - val_loss: 0.3549 - val_acc: 0.8300\n",
      "Epoch 66/100\n",
      "49/49 [==============================] - 2s 37ms/step - loss: 0.3648 - acc: 0.8234 - val_loss: 0.3553 - val_acc: 0.8303\n",
      "Epoch 67/100\n",
      "49/49 [==============================] - 2s 38ms/step - loss: 0.3630 - acc: 0.8236 - val_loss: 0.3544 - val_acc: 0.8292\n",
      "\n",
      " \n",
      "\n",
      "Training model with 500000 training points:\n",
      "Epoch 1/100\n",
      "123/123 [==============================] - 6s 38ms/step - loss: 0.6110 - acc: 0.6552 - val_loss: 0.5224 - val_acc: 0.7138\n",
      "Epoch 2/100\n",
      "123/123 [==============================] - 4s 35ms/step - loss: 0.5282 - acc: 0.7103 - val_loss: 0.4871 - val_acc: 0.7438\n",
      "Epoch 3/100\n",
      "123/123 [==============================] - 4s 36ms/step - loss: 0.4956 - acc: 0.7360 - val_loss: 0.4602 - val_acc: 0.7607\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 4s 35ms/step - loss: 0.4712 - acc: 0.7535 - val_loss: 0.4436 - val_acc: 0.7713\n",
      "Epoch 5/100\n",
      "123/123 [==============================] - 4s 35ms/step - loss: 0.4563 - acc: 0.7622 - val_loss: 0.4287 - val_acc: 0.7828\n",
      "Epoch 6/100\n",
      "123/123 [==============================] - 4s 35ms/step - loss: 0.4401 - acc: 0.7736 - val_loss: 0.4121 - val_acc: 0.7959\n",
      "Epoch 7/100\n",
      "123/123 [==============================] - 4s 35ms/step - loss: 0.4274 - acc: 0.7836 - val_loss: 0.3975 - val_acc: 0.8055\n",
      "Epoch 8/100\n",
      "123/123 [==============================] - 4s 35ms/step - loss: 0.4160 - acc: 0.7917 - val_loss: 0.3899 - val_acc: 0.8098\n",
      "Epoch 9/100\n",
      "123/123 [==============================] - 4s 36ms/step - loss: 0.4073 - acc: 0.7969 - val_loss: 0.3815 - val_acc: 0.8147\n",
      "Epoch 10/100\n",
      "123/123 [==============================] - 5s 37ms/step - loss: 0.4000 - acc: 0.8024 - val_loss: 0.3765 - val_acc: 0.8182\n",
      "Epoch 11/100\n",
      "123/123 [==============================] - 4s 36ms/step - loss: 0.3956 - acc: 0.8055 - val_loss: 0.3742 - val_acc: 0.8194\n",
      "Epoch 12/100\n",
      "123/123 [==============================] - 6s 47ms/step - loss: 0.3896 - acc: 0.8084 - val_loss: 0.3695 - val_acc: 0.8212\n",
      "Epoch 13/100\n",
      "123/123 [==============================] - 5s 41ms/step - loss: 0.3871 - acc: 0.8105 - val_loss: 0.3703 - val_acc: 0.8207\n",
      "Epoch 14/100\n",
      "123/123 [==============================] - 4s 36ms/step - loss: 0.3847 - acc: 0.8121 - val_loss: 0.3664 - val_acc: 0.8233\n",
      "Epoch 15/100\n",
      "123/123 [==============================] - 4s 36ms/step - loss: 0.3806 - acc: 0.8141 - val_loss: 0.3633 - val_acc: 0.8259\n",
      "Epoch 16/100\n",
      "123/123 [==============================] - 4s 36ms/step - loss: 0.3794 - acc: 0.8142 - val_loss: 0.3628 - val_acc: 0.8262\n",
      "Epoch 17/100\n",
      "123/123 [==============================] - 4s 36ms/step - loss: 0.3778 - acc: 0.8157 - val_loss: 0.3599 - val_acc: 0.8259\n",
      "Epoch 18/100\n",
      "123/123 [==============================] - 4s 36ms/step - loss: 0.3746 - acc: 0.8176 - val_loss: 0.3625 - val_acc: 0.8253\n",
      "Epoch 19/100\n",
      "123/123 [==============================] - 4s 36ms/step - loss: 0.3747 - acc: 0.8178 - val_loss: 0.3579 - val_acc: 0.8277\n",
      "Epoch 20/100\n",
      "123/123 [==============================] - 4s 36ms/step - loss: 0.3741 - acc: 0.8185 - val_loss: 0.3556 - val_acc: 0.8290\n",
      "Epoch 21/100\n",
      "123/123 [==============================] - 5s 41ms/step - loss: 0.3724 - acc: 0.8190 - val_loss: 0.3560 - val_acc: 0.8281\n",
      "Epoch 22/100\n",
      "123/123 [==============================] - 6s 50ms/step - loss: 0.3690 - acc: 0.8212 - val_loss: 0.3549 - val_acc: 0.8298\n",
      "Epoch 23/100\n",
      "123/123 [==============================] - 6s 50ms/step - loss: 0.3699 - acc: 0.8196 - val_loss: 0.3537 - val_acc: 0.8300\n",
      "Epoch 24/100\n",
      "123/123 [==============================] - 6s 47ms/step - loss: 0.3675 - acc: 0.8213 - val_loss: 0.3524 - val_acc: 0.8305\n",
      "Epoch 25/100\n",
      "123/123 [==============================] - 5s 41ms/step - loss: 0.3679 - acc: 0.8219 - val_loss: 0.3535 - val_acc: 0.8305\n",
      "Epoch 26/100\n",
      "123/123 [==============================] - 4s 35ms/step - loss: 0.3673 - acc: 0.8211 - val_loss: 0.3517 - val_acc: 0.8316\n",
      "Epoch 27/100\n",
      "123/123 [==============================] - 4s 36ms/step - loss: 0.3668 - acc: 0.8215 - val_loss: 0.3517 - val_acc: 0.8307\n",
      "Epoch 28/100\n",
      "123/123 [==============================] - 4s 36ms/step - loss: 0.3653 - acc: 0.8236 - val_loss: 0.3516 - val_acc: 0.8310\n",
      "Epoch 29/100\n",
      "123/123 [==============================] - 5s 39ms/step - loss: 0.3648 - acc: 0.8233 - val_loss: 0.3494 - val_acc: 0.8320\n",
      "Epoch 30/100\n",
      "123/123 [==============================] - 4s 36ms/step - loss: 0.3626 - acc: 0.8246 - val_loss: 0.3499 - val_acc: 0.8328\n",
      "Epoch 31/100\n",
      "123/123 [==============================] - 5s 40ms/step - loss: 0.3626 - acc: 0.8248 - val_loss: 0.3498 - val_acc: 0.8329\n",
      "Epoch 32/100\n",
      "123/123 [==============================] - 4s 35ms/step - loss: 0.3630 - acc: 0.8243 - val_loss: 0.3481 - val_acc: 0.8332\n",
      "Epoch 33/100\n",
      "123/123 [==============================] - 4s 35ms/step - loss: 0.3619 - acc: 0.8255 - val_loss: 0.3489 - val_acc: 0.8325\n",
      "Epoch 34/100\n",
      "123/123 [==============================] - 4s 35ms/step - loss: 0.3627 - acc: 0.8241 - val_loss: 0.3469 - val_acc: 0.8338\n",
      "Epoch 35/100\n",
      "123/123 [==============================] - 4s 36ms/step - loss: 0.3613 - acc: 0.8247 - val_loss: 0.3484 - val_acc: 0.8327\n",
      "Epoch 36/100\n",
      "123/123 [==============================] - 5s 37ms/step - loss: 0.3617 - acc: 0.8247 - val_loss: 0.3468 - val_acc: 0.8335\n",
      "Epoch 37/100\n",
      "123/123 [==============================] - 4s 36ms/step - loss: 0.3603 - acc: 0.8259 - val_loss: 0.3492 - val_acc: 0.8328\n",
      "Epoch 38/100\n",
      "123/123 [==============================] - 4s 37ms/step - loss: 0.3611 - acc: 0.8259 - val_loss: 0.3458 - val_acc: 0.8345\n",
      "Epoch 39/100\n",
      "123/123 [==============================] - 4s 36ms/step - loss: 0.3609 - acc: 0.8258 - val_loss: 0.3466 - val_acc: 0.8344\n",
      "Epoch 40/100\n",
      "123/123 [==============================] - 4s 35ms/step - loss: 0.3604 - acc: 0.8258 - val_loss: 0.3461 - val_acc: 0.8340\n",
      "Epoch 41/100\n",
      "123/123 [==============================] - 4s 35ms/step - loss: 0.3596 - acc: 0.8257 - val_loss: 0.3457 - val_acc: 0.8342\n",
      "Epoch 42/100\n",
      "123/123 [==============================] - 4s 35ms/step - loss: 0.3586 - acc: 0.8265 - val_loss: 0.3454 - val_acc: 0.8338\n",
      "Epoch 43/100\n",
      "123/123 [==============================] - 4s 35ms/step - loss: 0.3569 - acc: 0.8277 - val_loss: 0.3484 - val_acc: 0.8331\n",
      "\n",
      " \n",
      "\n",
      "Training model with 1000000 training points:\n",
      "Epoch 1/100\n",
      "245/245 [==============================] - 10s 36ms/step - loss: 0.5853 - acc: 0.6797 - val_loss: 0.4860 - val_acc: 0.7457\n",
      "Epoch 2/100\n",
      "245/245 [==============================] - 9s 35ms/step - loss: 0.4909 - acc: 0.7405 - val_loss: 0.4445 - val_acc: 0.7706\n",
      "Epoch 3/100\n",
      "245/245 [==============================] - 9s 35ms/step - loss: 0.4519 - acc: 0.7657 - val_loss: 0.4064 - val_acc: 0.8001\n",
      "Epoch 4/100\n",
      "245/245 [==============================] - 9s 36ms/step - loss: 0.4186 - acc: 0.7905 - val_loss: 0.3856 - val_acc: 0.8125\n",
      "Epoch 5/100\n",
      "245/245 [==============================] - 11s 43ms/step - loss: 0.4016 - acc: 0.8015 - val_loss: 0.3742 - val_acc: 0.8202\n",
      "Epoch 6/100\n",
      "245/245 [==============================] - 9s 35ms/step - loss: 0.3926 - acc: 0.8070 - val_loss: 0.3688 - val_acc: 0.8223\n",
      "Epoch 7/100\n",
      "245/245 [==============================] - 9s 35ms/step - loss: 0.3848 - acc: 0.8122 - val_loss: 0.3654 - val_acc: 0.8249\n",
      "Epoch 8/100\n",
      "245/245 [==============================] - 9s 35ms/step - loss: 0.3817 - acc: 0.8139 - val_loss: 0.3617 - val_acc: 0.8263\n",
      "Epoch 9/100\n",
      "245/245 [==============================] - 9s 36ms/step - loss: 0.3777 - acc: 0.8162 - val_loss: 0.3587 - val_acc: 0.8282\n",
      "Epoch 10/100\n",
      "245/245 [==============================] - 9s 36ms/step - loss: 0.3750 - acc: 0.8178 - val_loss: 0.3571 - val_acc: 0.8300\n",
      "Epoch 11/100\n",
      "245/245 [==============================] - 9s 35ms/step - loss: 0.3724 - acc: 0.8193 - val_loss: 0.3550 - val_acc: 0.8302\n",
      "Epoch 12/100\n",
      "245/245 [==============================] - 9s 35ms/step - loss: 0.3697 - acc: 0.8202 - val_loss: 0.3521 - val_acc: 0.8311\n",
      "Epoch 13/100\n",
      "245/245 [==============================] - 9s 35ms/step - loss: 0.3688 - acc: 0.8210 - val_loss: 0.3513 - val_acc: 0.8315\n",
      "Epoch 14/100\n",
      "245/245 [==============================] - 9s 35ms/step - loss: 0.3679 - acc: 0.8215 - val_loss: 0.3495 - val_acc: 0.8324\n",
      "Epoch 15/100\n",
      "245/245 [==============================] - 9s 35ms/step - loss: 0.3660 - acc: 0.8227 - val_loss: 0.3489 - val_acc: 0.8323\n",
      "Epoch 16/100\n",
      "245/245 [==============================] - 9s 39ms/step - loss: 0.3653 - acc: 0.8235 - val_loss: 0.3479 - val_acc: 0.8335\n",
      "Epoch 17/100\n",
      "245/245 [==============================] - 13s 52ms/step - loss: 0.3640 - acc: 0.8237 - val_loss: 0.3468 - val_acc: 0.8335\n",
      "Epoch 18/100\n",
      "245/245 [==============================] - 9s 37ms/step - loss: 0.3633 - acc: 0.8240 - val_loss: 0.3460 - val_acc: 0.8342\n",
      "Epoch 19/100\n",
      "245/245 [==============================] - 9s 36ms/step - loss: 0.3620 - acc: 0.8251 - val_loss: 0.3453 - val_acc: 0.8340\n",
      "Epoch 20/100\n",
      "245/245 [==============================] - 9s 35ms/step - loss: 0.3607 - acc: 0.8255 - val_loss: 0.3449 - val_acc: 0.8347\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 9s 36ms/step - loss: 0.3603 - acc: 0.8258 - val_loss: 0.3435 - val_acc: 0.8359\n",
      "Epoch 22/100\n",
      "245/245 [==============================] - 9s 35ms/step - loss: 0.3591 - acc: 0.8265 - val_loss: 0.3450 - val_acc: 0.8339\n",
      "Epoch 23/100\n",
      "245/245 [==============================] - 9s 37ms/step - loss: 0.3595 - acc: 0.8264 - val_loss: 0.3441 - val_acc: 0.8349\n",
      "Epoch 24/100\n",
      "245/245 [==============================] - 9s 36ms/step - loss: 0.3585 - acc: 0.8265 - val_loss: 0.3429 - val_acc: 0.8351\n",
      "Epoch 25/100\n",
      "245/245 [==============================] - 9s 37ms/step - loss: 0.3590 - acc: 0.8263 - val_loss: 0.3425 - val_acc: 0.8357\n",
      "Epoch 26/100\n",
      "245/245 [==============================] - 10s 39ms/step - loss: 0.3577 - acc: 0.8266 - val_loss: 0.3422 - val_acc: 0.8361\n",
      "Epoch 27/100\n",
      "245/245 [==============================] - 9s 38ms/step - loss: 0.3576 - acc: 0.8270 - val_loss: 0.3414 - val_acc: 0.8361\n",
      "Epoch 28/100\n",
      "245/245 [==============================] - 9s 37ms/step - loss: 0.3564 - acc: 0.8275 - val_loss: 0.3410 - val_acc: 0.8366\n",
      "Epoch 29/100\n",
      "245/245 [==============================] - 9s 36ms/step - loss: 0.3563 - acc: 0.8271 - val_loss: 0.3411 - val_acc: 0.8365\n",
      "Epoch 30/100\n",
      "245/245 [==============================] - 9s 36ms/step - loss: 0.3551 - acc: 0.8278 - val_loss: 0.3399 - val_acc: 0.8367\n",
      "Epoch 31/100\n",
      "245/245 [==============================] - 9s 36ms/step - loss: 0.3549 - acc: 0.8289 - val_loss: 0.3398 - val_acc: 0.8366\n",
      "Epoch 32/100\n",
      "245/245 [==============================] - 9s 36ms/step - loss: 0.3559 - acc: 0.8281 - val_loss: 0.3401 - val_acc: 0.8362\n",
      "Epoch 33/100\n",
      "245/245 [==============================] - 9s 36ms/step - loss: 0.3548 - acc: 0.8285 - val_loss: 0.3399 - val_acc: 0.8374\n",
      "Epoch 34/100\n",
      "245/245 [==============================] - 9s 36ms/step - loss: 0.3550 - acc: 0.8285 - val_loss: 0.3383 - val_acc: 0.8372\n",
      "Epoch 35/100\n",
      "245/245 [==============================] - 9s 36ms/step - loss: 0.3550 - acc: 0.8282 - val_loss: 0.3381 - val_acc: 0.8367\n",
      "Epoch 36/100\n",
      "245/245 [==============================] - 9s 36ms/step - loss: 0.3534 - acc: 0.8292 - val_loss: 0.3398 - val_acc: 0.8366\n",
      "Epoch 37/100\n",
      "245/245 [==============================] - 9s 36ms/step - loss: 0.3538 - acc: 0.8293 - val_loss: 0.3392 - val_acc: 0.8380\n",
      "Epoch 38/100\n",
      "245/245 [==============================] - 9s 36ms/step - loss: 0.3541 - acc: 0.8289 - val_loss: 0.3386 - val_acc: 0.8380\n",
      "Epoch 39/100\n",
      "245/245 [==============================] - 9s 36ms/step - loss: 0.3528 - acc: 0.8295 - val_loss: 0.3379 - val_acc: 0.8380\n",
      "Epoch 40/100\n",
      "245/245 [==============================] - 9s 36ms/step - loss: 0.3532 - acc: 0.8295 - val_loss: 0.3380 - val_acc: 0.8385\n",
      "Epoch 41/100\n",
      "245/245 [==============================] - 9s 36ms/step - loss: 0.3527 - acc: 0.8303 - val_loss: 0.3389 - val_acc: 0.8375\n",
      "Epoch 42/100\n",
      "245/245 [==============================] - 9s 36ms/step - loss: 0.3525 - acc: 0.8303 - val_loss: 0.3392 - val_acc: 0.8374\n",
      "Epoch 43/100\n",
      "245/245 [==============================] - 12s 49ms/step - loss: 0.3517 - acc: 0.8306 - val_loss: 0.3372 - val_acc: 0.8387\n",
      "Epoch 44/100\n",
      "245/245 [==============================] - 14s 56ms/step - loss: 0.3512 - acc: 0.8303 - val_loss: 0.3374 - val_acc: 0.8383\n",
      "Epoch 45/100\n",
      "245/245 [==============================] - 14s 57ms/step - loss: 0.3520 - acc: 0.8299 - val_loss: 0.3370 - val_acc: 0.8375\n",
      "Epoch 46/100\n",
      "245/245 [==============================] - 14s 57ms/step - loss: 0.3521 - acc: 0.8301 - val_loss: 0.3366 - val_acc: 0.8378\n",
      "Epoch 47/100\n",
      "245/245 [==============================] - 14s 56ms/step - loss: 0.3512 - acc: 0.8304 - val_loss: 0.3366 - val_acc: 0.8385\n",
      "Epoch 48/100\n",
      "245/245 [==============================] - 14s 57ms/step - loss: 0.3507 - acc: 0.8307 - val_loss: 0.3359 - val_acc: 0.8396\n",
      "Epoch 49/100\n",
      "245/245 [==============================] - 14s 57ms/step - loss: 0.3506 - acc: 0.8309 - val_loss: 0.3367 - val_acc: 0.8388\n",
      "Epoch 50/100\n",
      "245/245 [==============================] - 14s 56ms/step - loss: 0.3517 - acc: 0.8298 - val_loss: 0.3368 - val_acc: 0.8393\n",
      "Epoch 51/100\n",
      "245/245 [==============================] - 13s 55ms/step - loss: 0.3512 - acc: 0.8305 - val_loss: 0.3376 - val_acc: 0.8377\n",
      "Epoch 52/100\n",
      "245/245 [==============================] - 14s 56ms/step - loss: 0.3520 - acc: 0.8300 - val_loss: 0.3365 - val_acc: 0.8395\n",
      "Epoch 53/100\n",
      "245/245 [==============================] - 14s 57ms/step - loss: 0.3506 - acc: 0.8308 - val_loss: 0.3357 - val_acc: 0.8390\n",
      "\n",
      " \n",
      "\n",
      "Training model with 3339495 training points:\n",
      "Epoch 1/100\n",
      "816/816 [==============================] - 50s 58ms/step - loss: 0.5314 - acc: 0.7106 - val_loss: 0.3933 - val_acc: 0.8090\n",
      "Epoch 2/100\n",
      "816/816 [==============================] - 47s 58ms/step - loss: 0.4007 - acc: 0.8023 - val_loss: 0.3629 - val_acc: 0.8248\n",
      "Epoch 3/100\n",
      "816/816 [==============================] - 47s 57ms/step - loss: 0.3795 - acc: 0.8151 - val_loss: 0.3554 - val_acc: 0.8288\n",
      "Epoch 4/100\n",
      "816/816 [==============================] - 47s 58ms/step - loss: 0.3707 - acc: 0.8201 - val_loss: 0.3480 - val_acc: 0.8326\n",
      "Epoch 5/100\n",
      "816/816 [==============================] - 47s 57ms/step - loss: 0.3654 - acc: 0.8230 - val_loss: 0.3460 - val_acc: 0.8343\n",
      "Epoch 6/100\n",
      "816/816 [==============================] - 47s 58ms/step - loss: 0.3621 - acc: 0.8249 - val_loss: 0.3435 - val_acc: 0.8362\n",
      "Epoch 7/100\n",
      "816/816 [==============================] - 47s 57ms/step - loss: 0.3602 - acc: 0.8263 - val_loss: 0.3414 - val_acc: 0.8359\n",
      "Epoch 8/100\n",
      "816/816 [==============================] - 47s 57ms/step - loss: 0.3587 - acc: 0.8266 - val_loss: 0.3411 - val_acc: 0.8369\n",
      "Epoch 9/100\n",
      "816/816 [==============================] - 47s 57ms/step - loss: 0.3569 - acc: 0.8280 - val_loss: 0.3394 - val_acc: 0.8370\n",
      "Epoch 10/100\n",
      "816/816 [==============================] - 45s 56ms/step - loss: 0.3551 - acc: 0.8287 - val_loss: 0.3390 - val_acc: 0.8377\n",
      "Epoch 11/100\n",
      "816/816 [==============================] - 46s 57ms/step - loss: 0.3545 - acc: 0.8290 - val_loss: 0.3376 - val_acc: 0.8381\n",
      "Epoch 12/100\n",
      "816/816 [==============================] - 46s 56ms/step - loss: 0.3539 - acc: 0.8293 - val_loss: 0.3368 - val_acc: 0.8385\n",
      "Epoch 13/100\n",
      "816/816 [==============================] - 47s 58ms/step - loss: 0.3532 - acc: 0.8298 - val_loss: 0.3370 - val_acc: 0.8386\n",
      "Epoch 14/100\n",
      "816/816 [==============================] - 47s 58ms/step - loss: 0.3524 - acc: 0.8301 - val_loss: 0.3369 - val_acc: 0.8381\n",
      "Epoch 15/100\n",
      "816/816 [==============================] - 47s 58ms/step - loss: 0.3522 - acc: 0.8301 - val_loss: 0.3362 - val_acc: 0.8393\n",
      "Epoch 16/100\n",
      "816/816 [==============================] - 47s 57ms/step - loss: 0.3522 - acc: 0.8304 - val_loss: 0.3347 - val_acc: 0.8396\n",
      "Epoch 17/100\n",
      "816/816 [==============================] - 36s 44ms/step - loss: 0.3513 - acc: 0.8308 - val_loss: 0.3341 - val_acc: 0.8398\n",
      "Epoch 18/100\n",
      "816/816 [==============================] - 29s 36ms/step - loss: 0.3503 - acc: 0.8315 - val_loss: 0.3352 - val_acc: 0.8392\n",
      "Epoch 19/100\n",
      "816/816 [==============================] - 29s 36ms/step - loss: 0.3496 - acc: 0.8315 - val_loss: 0.3326 - val_acc: 0.8397\n",
      "Epoch 20/100\n",
      "816/816 [==============================] - 33s 40ms/step - loss: 0.3497 - acc: 0.8313 - val_loss: 0.3328 - val_acc: 0.8393\n",
      "Epoch 21/100\n",
      "816/816 [==============================] - 30s 37ms/step - loss: 0.3494 - acc: 0.8321 - val_loss: 0.3338 - val_acc: 0.8405\n",
      "Epoch 22/100\n",
      "816/816 [==============================] - 29s 36ms/step - loss: 0.3491 - acc: 0.8319 - val_loss: 0.3333 - val_acc: 0.8397\n",
      "Epoch 23/100\n",
      "816/816 [==============================] - 29s 36ms/step - loss: 0.3488 - acc: 0.8321 - val_loss: 0.3328 - val_acc: 0.8402\n",
      "Epoch 24/100\n",
      "816/816 [==============================] - 29s 36ms/step - loss: 0.3488 - acc: 0.8321 - val_loss: 0.3333 - val_acc: 0.8404\n",
      "Epoch 25/100\n",
      "816/816 [==============================] - 29s 36ms/step - loss: 0.3481 - acc: 0.8324 - val_loss: 0.3317 - val_acc: 0.8408\n",
      "Epoch 26/100\n",
      "816/816 [==============================] - 29s 35ms/step - loss: 0.3484 - acc: 0.8327 - val_loss: 0.3316 - val_acc: 0.8409\n",
      "Epoch 27/100\n",
      "816/816 [==============================] - 29s 36ms/step - loss: 0.3480 - acc: 0.8327 - val_loss: 0.3315 - val_acc: 0.8418\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816/816 [==============================] - 28s 35ms/step - loss: 0.3472 - acc: 0.8327 - val_loss: 0.3316 - val_acc: 0.8411\n",
      "Epoch 29/100\n",
      "816/816 [==============================] - 29s 35ms/step - loss: 0.3471 - acc: 0.8327 - val_loss: 0.3315 - val_acc: 0.8405\n",
      "Epoch 30/100\n",
      "816/816 [==============================] - 28s 35ms/step - loss: 0.3468 - acc: 0.8332 - val_loss: 0.3308 - val_acc: 0.8410\n",
      "Epoch 31/100\n",
      "816/816 [==============================] - 29s 36ms/step - loss: 0.3469 - acc: 0.8328 - val_loss: 0.3304 - val_acc: 0.8407\n",
      "Epoch 32/100\n",
      "816/816 [==============================] - 31s 38ms/step - loss: 0.3471 - acc: 0.8329 - val_loss: 0.3308 - val_acc: 0.8413\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_size = [100, 500, 1000, 2000, 5000,\n",
    "                 7500, 10_000, 12_500, 15_000, 20_000, 30_000, 50_000,\n",
    "                 100_000, 200_000, 500_000,\n",
    "                 1_000_000, x_train.shape[0]]\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "permuted_idx = np.random.permutation(x_train.shape[0])\n",
    "permuted_x = x_train[permuted_idx]\n",
    "permuted_y = Y_train[permuted_idx]\n",
    "\n",
    "for size in training_size:\n",
    "\n",
    "    x_sample = permuted_x[:size]\n",
    "    y_sample = permuted_y[:size]\n",
    "    \n",
    "    batch_size = size if size <= 10_000 else 4096\n",
    "    \n",
    "    print(f\"Training model with {size} training points:\")\n",
    "    model = nn_classifier_big()\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = 'acc')\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor = 'val_acc', patience = 5)\n",
    "    history = model.fit(x_sample,\n",
    "                        y_sample,\n",
    "                        validation_data = (x_val_sample, y_val_sample),\n",
    "                        batch_size = batch_size,\n",
    "                        epochs = 100,\n",
    "                        callbacks = [stop_early])\n",
    "    \n",
    "    train_losses.append(history.history['loss'])\n",
    "    val_losses.append(history.history['val_loss'])\n",
    "    \n",
    "    train_accuracies.append(history.history['acc'])\n",
    "    val_accuracies.append(history.history['val_acc'])\n",
    "    \n",
    "    print(\"\\n \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "263ac942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_ = [x[-1] for x in val_losses]\n",
    "acc_ = [x[-1] for x in val_accuracies]\n",
    "\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "\n",
    "plt.plot(training_size, acc_, \"-o\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Number of Training Points\");\n",
    "plt.ylabel(\"Validation Accuracy\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cd88ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
