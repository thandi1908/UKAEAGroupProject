{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.pipeline_tools import (\n",
    "    prepare_data,\n",
    "    regressor_uncertainty,\n",
    "    select_unstable_data,\n",
    "    retrain_regressor,\n",
    "    uncertainty_change,\n",
    "    mse_change,\n",
    ")\n",
    "from scripts.Models import ITGDatasetDF, load_model, ITGDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader\n",
    "from scripts.utils import train_keys\n",
    "import copy\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pipeline_config.yaml') as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "pretrained = cfg['pretrained']\n",
    "paths = cfg['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = prepare_data(\n",
    "    paths['train'], paths['validation'], target_column=\"efiitg_gb\", target_var=\"itg\"\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(train_data.drop([\"itg\"], axis=1))\n",
    "\n",
    "train_dataset = ITGDatasetDF(train_data, target_column=\"efiitg_gb\", target_var=\"itg\")\n",
    "valid_dataset = ITGDatasetDF(val_data, target_column=\"efiitg_gb\", target_var=\"itg\")\n",
    "\n",
    "# # TODO: further testing of the scale function\n",
    "train_dataset.scale(scaler)\n",
    "valid_dataset.scale(scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained models\n",
    "print(\"Loaded the following models:\\n\")\n",
    "models = {}\n",
    "for model in pretrained:\n",
    "    if pretrained[model][\"trained\"] == True:\n",
    "        trained_model = load_model(model, pretrained[model][\"save_path\"])\n",
    "        models[model] = trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Needs to be the true training samples used!!!\n",
    "train_sample = train_dataset.sample(10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "init_epoch = 25\n",
    "iterations = 4\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "n_train_points = []\n",
    "mse_before = []\n",
    "mse_after = []\n",
    "d_mse = []\n",
    "d_train_uncert = []\n",
    "\n",
    "for i in range(iterations):\n",
    "    print(f\"\\nIteration: {i}\\n\")\n",
    "    valid_sample = valid_dataset.sample(10_000)\n",
    "\n",
    "    # remove the sampled data points from the dataset\n",
    "    valid_dataset.remove(valid_sample.data.index)\n",
    "    \n",
    "    print(\"\\nRunning Classifier...\\n\")\n",
    "\n",
    "    select_unstable_data(valid_sample, batch_size=100, classifier=models[\"ITG_class\"])\n",
    "    \n",
    "    print(\"\\nGetting Regressor Uncertainties...\\n\")\n",
    "\n",
    "    uncertain_datset, uncert_before, data_idx = regressor_uncertainty(\n",
    "    valid_sample, models[\"ITG_reg\"], n_runs=15, keep=0.25,valid_dataset=valid_dataset\n",
    ")\n",
    "    train_sample_origin, train_uncert_before, train_uncert_idx = regressor_uncertainty(\n",
    "        train_sample, models[\"ITG_reg\"], n_runs=15,train_data=True,\n",
    "        )\n",
    "\n",
    "    train_sample.add(uncertain_datset)\n",
    "\n",
    "    uncertain_loader = DataLoader(train_sample, batch_size=len(train_sample), shuffle=True)\n",
    "    \n",
    "    print(\"\\nGetting Regressor Predictions...\\n\")\n",
    "\n",
    "    prediction_before, prediction_idx_order = models[\"ITG_reg\"].predict(uncertain_loader)\n",
    "\n",
    "    # Switching validation dataset to numpy arrays to see if it is quicker\n",
    "    x_array = valid_dataset.data[train_keys].values\n",
    "    y_array = valid_dataset.data[\"itg\"].values\n",
    "    z_array = valid_dataset.data[\"efiitg_gb\"].values\n",
    "    dataset_numpy = ITGDataset(x_array, y_array, z_array)\n",
    "    valid_loader = DataLoader(\n",
    "        dataset_numpy, batch_size=int(0.1 * len(y_array)), shuffle=True\n",
    "    )\n",
    "\n",
    "    # Retrain Regressor (Further research required)\n",
    "    print(\"\\nRetraining Regressor...\\n\")\n",
    "    epochs = init_epoch * (i+1)\n",
    "    train_loss, test_loss = retrain_regressor(\n",
    "        uncertain_loader,\n",
    "        valid_loader,\n",
    "        models[\"ITG_reg\"],\n",
    "        learning_rate=1e-3,\n",
    "        epochs=epochs,\n",
    "        validation_step=True,\n",
    "        lam = 0.6\n",
    "    )\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    print(\"\\nGetting Regressor Predictions...\\n\")\n",
    "    \n",
    "    prediction_after,_ = models[\"ITG_reg\"].predict(uncertain_loader, prediction_idx_order)\n",
    "\n",
    "    _, uncert_after,_ = regressor_uncertainty(valid_sample, models[\"ITG_reg\"], n_runs=15, keep=0.25, order_idx=data_idx)\n",
    "    _, train_uncert_after,_ = regressor_uncertainty(train_sample_origin, models[\"ITG_reg\"], n_runs=15,order_idx=train_uncert_idx, train_data=True)\n",
    "   \n",
    "    print(\"\\nNovel Data Uncertainty changes...\\n\")\n",
    "    _ = uncertainty_change(x=uncert_before, y=uncert_after)\n",
    "\n",
    "    print(\"\\nTraining Data Uncertainty changes...\\n\")\n",
    "    \n",
    "    d_train_uncert.append(uncertainty_change(x=train_uncert_before, y=train_uncert_after))\n",
    "    \n",
    "    _ = mse_change(prediction_before, prediction_after,prediction_idx_order,data_idx, uncertain_loader,[uncert_before, uncert_after])\n",
    "\n",
    "    train_mse_before, train_mse_after, delta_mse = mse_change(\n",
    "    prediction_before,\n",
    "    prediction_after,\n",
    "    prediction_idx_order,\n",
    "    train_uncert_idx,\n",
    "    uncertain_loader,\n",
    "    uncertainties=[train_uncert_before, train_uncert_after],\n",
    "    data=\"train\"\n",
    "     )\n",
    "    mse_before.append(train_mse_before)\n",
    "    mse_after.append(train_mse_after)\n",
    "    d_mse.append(delta_mse)\n",
    "    print(len(prediction_idx_order))\n",
    "    n_train_points.append(len(prediction_idx_order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(len(train_losses)):\n",
    "    plt.scatter(np.arange(0,len(train_losses[i])), train_losses[i], label =f\"Iteration {i}\");\n",
    "    plt.legend()\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Training Loss\");\n",
    "plt.savefig(\"SP_training_loss.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(len(test_losses)):\n",
    "    plt.plot(np.arange(0,len(test_losses[i])), test_losses[i]);\n",
    "    plt.scatter(np.arange(0,len(test_losses[i])), test_losses[i], label = f\"Iteration {i}\");\n",
    "    \n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Test Loss\");\n",
    "plt.savefig(\"SP_test_loss.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "35c235ff99f8605ca4fe7a283017706943881a3c0b9b82454bde1f1c1c4aedb1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
