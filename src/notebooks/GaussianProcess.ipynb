{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69e9e899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c976f7",
   "metadata": {},
   "source": [
    "###  Loading and pre-processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c322ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle(\"/share/rcifdata/jbarr/UKAEAGroupProject/data/QLKNN_train_data.pkl\") \n",
    "train_data = train_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d50e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = train_data.iloc[:,:15]\n",
    "y_data = train_data.iloc[:,15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71dc1cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing one input dimension and one output dimension as random\n",
    "input_dim = np.random.permutation(list(x_data.columns))\n",
    "output_dim = np.random.permutation(list(y_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef7baec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension to use: x\n",
      "Input dimension to use: efitem_gb_div_efetem_gb\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input dimension to use: {input_dim[0]}\")\n",
    "print(f\"Input dimension to use: {output_dim[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e6e26c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data = x_data[f'{input_dim[0]}']\n",
    "y_train_data = y_data[f'{output_dim[0]}']\n",
    "\n",
    "assert x_train_data.shape[0] == y_train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a6e4dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "idx = np.random.permutation(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fc36674",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data = torch.tensor(x_train_data.values)[idx]\n",
    "y_train_data = torch.tensor(y_train_data.values)[idx]\n",
    "\n",
    "x_min, x_max = x_train_data.min(), x_train_data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f6205de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e11f4c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(x_train_data, y_train_data, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c08e2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/250 - Loss: 1.089   lengthscale: 0.693   noise: 0.693\n",
      "Iter 2/250 - Loss: 1.074   lengthscale: 0.744   noise: 0.644\n",
      "Iter 3/250 - Loss: 1.061   lengthscale: 0.798   noise: 0.598\n",
      "Iter 4/250 - Loss: 1.050   lengthscale: 0.853   noise: 0.555\n",
      "Iter 5/250 - Loss: 1.041   lengthscale: 0.910   noise: 0.515\n",
      "Iter 6/250 - Loss: 1.035   lengthscale: 0.968   noise: 0.479\n",
      "Iter 7/250 - Loss: 1.031   lengthscale: 1.027   noise: 0.447\n",
      "Iter 8/250 - Loss: 1.030   lengthscale: 1.086   noise: 0.420\n",
      "Iter 9/250 - Loss: 1.030   lengthscale: 1.145   noise: 0.398\n",
      "Iter 10/250 - Loss: 1.031   lengthscale: 1.203   noise: 0.383\n",
      "Iter 11/250 - Loss: 1.032   lengthscale: 1.260   noise: 0.374\n",
      "Iter 12/250 - Loss: 1.032   lengthscale: 1.315   noise: 0.371\n",
      "Iter 13/250 - Loss: 1.031   lengthscale: 1.368   noise: 0.373\n",
      "Iter 14/250 - Loss: 1.030   lengthscale: 1.418   noise: 0.378\n",
      "Iter 15/250 - Loss: 1.028   lengthscale: 1.464   noise: 0.387\n",
      "Iter 16/250 - Loss: 1.026   lengthscale: 1.508   noise: 0.397\n",
      "Iter 17/250 - Loss: 1.025   lengthscale: 1.548   noise: 0.410\n",
      "Iter 18/250 - Loss: 1.024   lengthscale: 1.586   noise: 0.423\n",
      "Iter 19/250 - Loss: 1.023   lengthscale: 1.620   noise: 0.436\n",
      "Iter 20/250 - Loss: 1.022   lengthscale: 1.651   noise: 0.448\n",
      "Iter 21/250 - Loss: 1.022   lengthscale: 1.680   noise: 0.459\n",
      "Iter 22/250 - Loss: 1.021   lengthscale: 1.706   noise: 0.468\n",
      "Iter 23/250 - Loss: 1.021   lengthscale: 1.730   noise: 0.474\n",
      "Iter 24/250 - Loss: 1.021   lengthscale: 1.752   noise: 0.478\n",
      "Iter 25/250 - Loss: 1.020   lengthscale: 1.772   noise: 0.479\n",
      "Iter 26/250 - Loss: 1.020   lengthscale: 1.791   noise: 0.478\n",
      "Iter 27/250 - Loss: 1.020   lengthscale: 1.808   noise: 0.475\n",
      "Iter 28/250 - Loss: 1.019   lengthscale: 1.824   noise: 0.469\n",
      "Iter 29/250 - Loss: 1.018   lengthscale: 1.839   noise: 0.463\n",
      "Iter 30/250 - Loss: 1.017   lengthscale: 1.852   noise: 0.456\n",
      "Iter 31/250 - Loss: 1.016   lengthscale: 1.864   noise: 0.448\n",
      "Iter 32/250 - Loss: 1.015   lengthscale: 1.876   noise: 0.441\n",
      "Iter 33/250 - Loss: 1.015   lengthscale: 1.886   noise: 0.434\n",
      "Iter 34/250 - Loss: 1.015   lengthscale: 1.895   noise: 0.428\n",
      "Iter 35/250 - Loss: 1.015   lengthscale: 1.903   noise: 0.424\n",
      "Iter 36/250 - Loss: 1.015   lengthscale: 1.910   noise: 0.421\n",
      "Iter 37/250 - Loss: 1.014   lengthscale: 1.916   noise: 0.419\n",
      "Iter 38/250 - Loss: 1.013   lengthscale: 1.922   noise: 0.419\n",
      "Iter 39/250 - Loss: 1.013   lengthscale: 1.926   noise: 0.421\n",
      "Iter 40/250 - Loss: 1.012   lengthscale: 1.930   noise: 0.423\n",
      "Iter 41/250 - Loss: 1.012   lengthscale: 1.934   noise: 0.427\n",
      "Iter 42/250 - Loss: 1.011   lengthscale: 1.937   noise: 0.431\n",
      "Iter 43/250 - Loss: 1.011   lengthscale: 1.940   noise: 0.435\n",
      "Iter 44/250 - Loss: 1.010   lengthscale: 1.943   noise: 0.439\n",
      "Iter 45/250 - Loss: 1.010   lengthscale: 1.945   noise: 0.443\n",
      "Iter 46/250 - Loss: 1.010   lengthscale: 1.947   noise: 0.446\n",
      "Iter 47/250 - Loss: 1.009   lengthscale: 1.949   noise: 0.448\n",
      "Iter 48/250 - Loss: 1.009   lengthscale: 1.950   noise: 0.450\n",
      "Iter 49/250 - Loss: 1.009   lengthscale: 1.951   noise: 0.450\n",
      "Iter 50/250 - Loss: 1.009   lengthscale: 1.952   noise: 0.450\n",
      "Iter 51/250 - Loss: 1.008   lengthscale: 1.953   noise: 0.448\n",
      "Iter 52/250 - Loss: 1.008   lengthscale: 1.953   noise: 0.446\n",
      "Iter 53/250 - Loss: 1.008   lengthscale: 1.954   noise: 0.444\n",
      "Iter 54/250 - Loss: 1.007   lengthscale: 1.954   noise: 0.441\n",
      "Iter 55/250 - Loss: 1.007   lengthscale: 1.955   noise: 0.438\n",
      "Iter 56/250 - Loss: 1.007   lengthscale: 1.955   noise: 0.436\n",
      "Iter 57/250 - Loss: 1.007   lengthscale: 1.955   noise: 0.434\n",
      "Iter 58/250 - Loss: 1.006   lengthscale: 1.955   noise: 0.432\n",
      "Iter 59/250 - Loss: 1.006   lengthscale: 1.955   noise: 0.431\n",
      "Iter 60/250 - Loss: 1.006   lengthscale: 1.955   noise: 0.431\n",
      "Iter 61/250 - Loss: 1.006   lengthscale: 1.954   noise: 0.431\n",
      "Iter 62/250 - Loss: 1.006   lengthscale: 1.954   noise: 0.432\n",
      "Iter 63/250 - Loss: 1.006   lengthscale: 1.954   noise: 0.433\n",
      "Iter 64/250 - Loss: 1.005   lengthscale: 1.954   noise: 0.434\n",
      "Iter 65/250 - Loss: 1.005   lengthscale: 1.953   noise: 0.436\n",
      "Iter 66/250 - Loss: 1.005   lengthscale: 1.953   noise: 0.437\n",
      "Iter 67/250 - Loss: 1.005   lengthscale: 1.953   noise: 0.439\n",
      "Iter 68/250 - Loss: 1.005   lengthscale: 1.952   noise: 0.440\n",
      "Iter 69/250 - Loss: 1.005   lengthscale: 1.952   noise: 0.440\n",
      "Iter 70/250 - Loss: 1.005   lengthscale: 1.951   noise: 0.441\n",
      "Iter 71/250 - Loss: 1.005   lengthscale: 1.951   noise: 0.440\n",
      "Iter 72/250 - Loss: 1.005   lengthscale: 1.951   noise: 0.440\n",
      "Iter 73/250 - Loss: 1.005   lengthscale: 1.950   noise: 0.439\n",
      "Iter 74/250 - Loss: 1.005   lengthscale: 1.950   noise: 0.438\n",
      "Iter 75/250 - Loss: 1.005   lengthscale: 1.949   noise: 0.437\n",
      "Iter 76/250 - Loss: 1.004   lengthscale: 1.949   noise: 0.436\n",
      "Iter 77/250 - Loss: 1.004   lengthscale: 1.949   noise: 0.435\n",
      "Iter 78/250 - Loss: 1.004   lengthscale: 1.948   noise: 0.435\n",
      "Iter 79/250 - Loss: 1.004   lengthscale: 1.948   noise: 0.434\n",
      "Iter 80/250 - Loss: 1.004   lengthscale: 1.948   noise: 0.434\n",
      "Iter 81/250 - Loss: 1.004   lengthscale: 1.947   noise: 0.434\n",
      "Iter 82/250 - Loss: 1.004   lengthscale: 1.947   noise: 0.434\n",
      "Iter 83/250 - Loss: 1.004   lengthscale: 1.946   noise: 0.435\n",
      "Iter 84/250 - Loss: 1.004   lengthscale: 1.946   noise: 0.435\n",
      "Iter 85/250 - Loss: 1.004   lengthscale: 1.946   noise: 0.436\n",
      "Iter 86/250 - Loss: 1.004   lengthscale: 1.945   noise: 0.436\n",
      "Iter 87/250 - Loss: 1.004   lengthscale: 1.945   noise: 0.437\n",
      "Iter 88/250 - Loss: 1.004   lengthscale: 1.945   noise: 0.437\n",
      "Iter 89/250 - Loss: 1.004   lengthscale: 1.944   noise: 0.437\n",
      "Iter 90/250 - Loss: 1.004   lengthscale: 1.944   noise: 0.437\n",
      "Iter 91/250 - Loss: 1.004   lengthscale: 1.944   noise: 0.437\n",
      "Iter 92/250 - Loss: 1.004   lengthscale: 1.944   noise: 0.437\n",
      "Iter 93/250 - Loss: 1.004   lengthscale: 1.943   noise: 0.437\n",
      "Iter 94/250 - Loss: 1.004   lengthscale: 1.943   noise: 0.436\n",
      "Iter 95/250 - Loss: 1.004   lengthscale: 1.943   noise: 0.436\n",
      "Iter 96/250 - Loss: 1.004   lengthscale: 1.942   noise: 0.436\n",
      "Iter 97/250 - Loss: 1.004   lengthscale: 1.942   noise: 0.435\n",
      "Iter 98/250 - Loss: 1.004   lengthscale: 1.942   noise: 0.435\n",
      "Iter 99/250 - Loss: 1.004   lengthscale: 1.942   noise: 0.435\n",
      "Iter 100/250 - Loss: 1.004   lengthscale: 1.941   noise: 0.435\n",
      "Iter 101/250 - Loss: 1.004   lengthscale: 1.941   noise: 0.435\n",
      "Iter 102/250 - Loss: 1.004   lengthscale: 1.941   noise: 0.435\n",
      "Iter 103/250 - Loss: 1.004   lengthscale: 1.941   noise: 0.436\n",
      "Iter 104/250 - Loss: 1.004   lengthscale: 1.940   noise: 0.436\n",
      "Iter 105/250 - Loss: 1.004   lengthscale: 1.940   noise: 0.436\n",
      "Iter 106/250 - Loss: 1.004   lengthscale: 1.940   noise: 0.436\n",
      "Iter 107/250 - Loss: 1.004   lengthscale: 1.940   noise: 0.436\n",
      "Iter 108/250 - Loss: 1.004   lengthscale: 1.940   noise: 0.436\n",
      "Iter 109/250 - Loss: 1.004   lengthscale: 1.939   noise: 0.436\n",
      "Iter 110/250 - Loss: 1.004   lengthscale: 1.939   noise: 0.436\n",
      "Iter 111/250 - Loss: 1.004   lengthscale: 1.939   noise: 0.436\n",
      "Iter 112/250 - Loss: 1.004   lengthscale: 1.939   noise: 0.436\n",
      "Iter 113/250 - Loss: 1.004   lengthscale: 1.939   noise: 0.436\n",
      "Iter 114/250 - Loss: 1.004   lengthscale: 1.938   noise: 0.436\n",
      "Iter 115/250 - Loss: 1.004   lengthscale: 1.938   noise: 0.436\n",
      "Iter 116/250 - Loss: 1.004   lengthscale: 1.938   noise: 0.435\n",
      "Iter 117/250 - Loss: 1.004   lengthscale: 1.938   noise: 0.435\n",
      "Iter 118/250 - Loss: 1.004   lengthscale: 1.938   noise: 0.435\n",
      "Iter 119/250 - Loss: 1.004   lengthscale: 1.937   noise: 0.435\n",
      "Iter 120/250 - Loss: 1.004   lengthscale: 1.937   noise: 0.436\n",
      "Iter 121/250 - Loss: 1.004   lengthscale: 1.937   noise: 0.436\n",
      "Iter 122/250 - Loss: 1.004   lengthscale: 1.937   noise: 0.436\n",
      "Iter 123/250 - Loss: 1.004   lengthscale: 1.937   noise: 0.436\n",
      "Iter 124/250 - Loss: 1.004   lengthscale: 1.937   noise: 0.436\n",
      "Iter 125/250 - Loss: 1.004   lengthscale: 1.936   noise: 0.436\n",
      "Iter 126/250 - Loss: 1.004   lengthscale: 1.936   noise: 0.436\n",
      "Iter 127/250 - Loss: 1.004   lengthscale: 1.936   noise: 0.436\n",
      "Iter 128/250 - Loss: 1.004   lengthscale: 1.936   noise: 0.436\n",
      "Iter 129/250 - Loss: 1.004   lengthscale: 1.936   noise: 0.436\n",
      "Iter 130/250 - Loss: 1.004   lengthscale: 1.936   noise: 0.436\n",
      "Iter 131/250 - Loss: 1.004   lengthscale: 1.935   noise: 0.436\n",
      "Iter 132/250 - Loss: 1.004   lengthscale: 1.935   noise: 0.436\n",
      "Iter 133/250 - Loss: 1.004   lengthscale: 1.935   noise: 0.436\n",
      "Iter 134/250 - Loss: 1.004   lengthscale: 1.935   noise: 0.436\n",
      "Iter 135/250 - Loss: 1.004   lengthscale: 1.935   noise: 0.436\n",
      "Iter 136/250 - Loss: 1.004   lengthscale: 1.935   noise: 0.436\n",
      "Iter 137/250 - Loss: 1.004   lengthscale: 1.935   noise: 0.436\n",
      "Iter 138/250 - Loss: 1.004   lengthscale: 1.934   noise: 0.436\n",
      "Iter 139/250 - Loss: 1.004   lengthscale: 1.934   noise: 0.436\n",
      "Iter 140/250 - Loss: 1.004   lengthscale: 1.934   noise: 0.436\n",
      "Iter 141/250 - Loss: 1.004   lengthscale: 1.934   noise: 0.436\n",
      "Iter 142/250 - Loss: 1.004   lengthscale: 1.934   noise: 0.436\n",
      "Iter 143/250 - Loss: 1.004   lengthscale: 1.934   noise: 0.436\n",
      "Iter 144/250 - Loss: 1.004   lengthscale: 1.934   noise: 0.436\n",
      "Iter 145/250 - Loss: 1.004   lengthscale: 1.934   noise: 0.436\n",
      "Iter 146/250 - Loss: 1.003   lengthscale: 1.933   noise: 0.436\n",
      "Iter 147/250 - Loss: 1.003   lengthscale: 1.933   noise: 0.436\n",
      "Iter 148/250 - Loss: 1.003   lengthscale: 1.933   noise: 0.436\n",
      "Iter 149/250 - Loss: 1.003   lengthscale: 1.933   noise: 0.436\n",
      "Iter 150/250 - Loss: 1.003   lengthscale: 1.933   noise: 0.436\n",
      "Iter 151/250 - Loss: 1.003   lengthscale: 1.933   noise: 0.436\n",
      "Iter 152/250 - Loss: 1.003   lengthscale: 1.933   noise: 0.436\n",
      "Iter 153/250 - Loss: 1.003   lengthscale: 1.933   noise: 0.436\n",
      "Iter 154/250 - Loss: 1.003   lengthscale: 1.932   noise: 0.436\n",
      "Iter 155/250 - Loss: 1.003   lengthscale: 1.932   noise: 0.436\n",
      "Iter 156/250 - Loss: 1.003   lengthscale: 1.932   noise: 0.436\n",
      "Iter 157/250 - Loss: 1.003   lengthscale: 1.932   noise: 0.436\n",
      "Iter 158/250 - Loss: 1.003   lengthscale: 1.932   noise: 0.436\n",
      "Iter 159/250 - Loss: 1.003   lengthscale: 1.932   noise: 0.436\n",
      "Iter 160/250 - Loss: 1.003   lengthscale: 1.932   noise: 0.436\n",
      "Iter 161/250 - Loss: 1.003   lengthscale: 1.932   noise: 0.436\n",
      "Iter 162/250 - Loss: 1.003   lengthscale: 1.931   noise: 0.436\n",
      "Iter 163/250 - Loss: 1.003   lengthscale: 1.931   noise: 0.436\n",
      "Iter 164/250 - Loss: 1.003   lengthscale: 1.931   noise: 0.436\n",
      "Iter 165/250 - Loss: 1.003   lengthscale: 1.931   noise: 0.436\n",
      "Iter 166/250 - Loss: 1.003   lengthscale: 1.931   noise: 0.436\n",
      "Iter 167/250 - Loss: 1.003   lengthscale: 1.931   noise: 0.436\n",
      "Iter 168/250 - Loss: 1.003   lengthscale: 1.931   noise: 0.436\n",
      "Iter 169/250 - Loss: 1.003   lengthscale: 1.931   noise: 0.436\n",
      "Iter 170/250 - Loss: 1.003   lengthscale: 1.931   noise: 0.436\n",
      "Iter 171/250 - Loss: 1.003   lengthscale: 1.931   noise: 0.436\n",
      "Iter 172/250 - Loss: 1.003   lengthscale: 1.930   noise: 0.436\n",
      "Iter 173/250 - Loss: 1.003   lengthscale: 1.930   noise: 0.436\n",
      "Iter 174/250 - Loss: 1.003   lengthscale: 1.930   noise: 0.436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 175/250 - Loss: 1.003   lengthscale: 1.930   noise: 0.436\n",
      "Iter 176/250 - Loss: 1.003   lengthscale: 1.930   noise: 0.436\n",
      "Iter 177/250 - Loss: 1.003   lengthscale: 1.930   noise: 0.436\n",
      "Iter 178/250 - Loss: 1.003   lengthscale: 1.930   noise: 0.436\n",
      "Iter 179/250 - Loss: 1.003   lengthscale: 1.930   noise: 0.436\n",
      "Iter 180/250 - Loss: 1.003   lengthscale: 1.930   noise: 0.436\n",
      "Iter 181/250 - Loss: 1.003   lengthscale: 1.929   noise: 0.436\n",
      "Iter 182/250 - Loss: 1.003   lengthscale: 1.929   noise: 0.436\n",
      "Iter 183/250 - Loss: 1.003   lengthscale: 1.929   noise: 0.436\n",
      "Iter 184/250 - Loss: 1.003   lengthscale: 1.929   noise: 0.436\n",
      "Iter 185/250 - Loss: 1.003   lengthscale: 1.929   noise: 0.436\n",
      "Iter 186/250 - Loss: 1.003   lengthscale: 1.929   noise: 0.436\n",
      "Iter 187/250 - Loss: 1.003   lengthscale: 1.929   noise: 0.436\n",
      "Iter 188/250 - Loss: 1.003   lengthscale: 1.929   noise: 0.436\n",
      "Iter 189/250 - Loss: 1.003   lengthscale: 1.929   noise: 0.436\n",
      "Iter 190/250 - Loss: 1.003   lengthscale: 1.929   noise: 0.436\n",
      "Iter 191/250 - Loss: 1.003   lengthscale: 1.929   noise: 0.436\n",
      "Iter 192/250 - Loss: 1.003   lengthscale: 1.928   noise: 0.436\n",
      "Iter 193/250 - Loss: 1.003   lengthscale: 1.928   noise: 0.436\n",
      "Iter 194/250 - Loss: 1.003   lengthscale: 1.928   noise: 0.436\n",
      "Iter 195/250 - Loss: 1.003   lengthscale: 1.928   noise: 0.436\n",
      "Iter 196/250 - Loss: 1.003   lengthscale: 1.928   noise: 0.436\n",
      "Iter 197/250 - Loss: 1.003   lengthscale: 1.928   noise: 0.436\n",
      "Iter 198/250 - Loss: 1.003   lengthscale: 1.928   noise: 0.436\n",
      "Iter 199/250 - Loss: 1.003   lengthscale: 1.928   noise: 0.436\n",
      "Iter 200/250 - Loss: 1.003   lengthscale: 1.928   noise: 0.436\n",
      "Iter 201/250 - Loss: 1.003   lengthscale: 1.928   noise: 0.436\n",
      "Iter 202/250 - Loss: 1.003   lengthscale: 1.928   noise: 0.436\n",
      "Iter 203/250 - Loss: 1.003   lengthscale: 1.927   noise: 0.436\n",
      "Iter 204/250 - Loss: 1.003   lengthscale: 1.927   noise: 0.436\n",
      "Iter 205/250 - Loss: 1.003   lengthscale: 1.927   noise: 0.436\n",
      "Iter 206/250 - Loss: 1.003   lengthscale: 1.927   noise: 0.436\n",
      "Iter 207/250 - Loss: 1.003   lengthscale: 1.927   noise: 0.436\n",
      "Iter 208/250 - Loss: 1.003   lengthscale: 1.927   noise: 0.436\n",
      "Iter 209/250 - Loss: 1.003   lengthscale: 1.927   noise: 0.436\n",
      "Iter 210/250 - Loss: 1.003   lengthscale: 1.927   noise: 0.436\n",
      "Iter 211/250 - Loss: 1.003   lengthscale: 1.927   noise: 0.436\n",
      "Iter 212/250 - Loss: 1.003   lengthscale: 1.927   noise: 0.436\n",
      "Iter 213/250 - Loss: 1.003   lengthscale: 1.927   noise: 0.436\n",
      "Iter 214/250 - Loss: 1.003   lengthscale: 1.927   noise: 0.436\n",
      "Iter 215/250 - Loss: 1.003   lengthscale: 1.926   noise: 0.436\n",
      "Iter 216/250 - Loss: 1.003   lengthscale: 1.926   noise: 0.436\n",
      "Iter 217/250 - Loss: 1.003   lengthscale: 1.926   noise: 0.436\n",
      "Iter 218/250 - Loss: 1.003   lengthscale: 1.926   noise: 0.436\n",
      "Iter 219/250 - Loss: 1.003   lengthscale: 1.926   noise: 0.436\n",
      "Iter 220/250 - Loss: 1.003   lengthscale: 1.926   noise: 0.436\n",
      "Iter 221/250 - Loss: 1.003   lengthscale: 1.926   noise: 0.436\n",
      "Iter 222/250 - Loss: 1.003   lengthscale: 1.926   noise: 0.436\n",
      "Iter 223/250 - Loss: 1.003   lengthscale: 1.926   noise: 0.436\n",
      "Iter 224/250 - Loss: 1.003   lengthscale: 1.926   noise: 0.436\n",
      "Iter 225/250 - Loss: 1.003   lengthscale: 1.926   noise: 0.436\n",
      "Iter 226/250 - Loss: 1.003   lengthscale: 1.926   noise: 0.436\n",
      "Iter 227/250 - Loss: 1.003   lengthscale: 1.926   noise: 0.436\n",
      "Iter 228/250 - Loss: 1.003   lengthscale: 1.925   noise: 0.436\n",
      "Iter 229/250 - Loss: 1.003   lengthscale: 1.925   noise: 0.436\n",
      "Iter 230/250 - Loss: 1.003   lengthscale: 1.925   noise: 0.436\n",
      "Iter 231/250 - Loss: 1.003   lengthscale: 1.925   noise: 0.436\n",
      "Iter 232/250 - Loss: 1.003   lengthscale: 1.925   noise: 0.436\n",
      "Iter 233/250 - Loss: 1.003   lengthscale: 1.925   noise: 0.436\n",
      "Iter 234/250 - Loss: 1.003   lengthscale: 1.925   noise: 0.436\n",
      "Iter 235/250 - Loss: 1.003   lengthscale: 1.925   noise: 0.436\n",
      "Iter 236/250 - Loss: 1.003   lengthscale: 1.925   noise: 0.436\n",
      "Iter 237/250 - Loss: 1.003   lengthscale: 1.925   noise: 0.436\n",
      "Iter 238/250 - Loss: 1.003   lengthscale: 1.925   noise: 0.436\n",
      "Iter 239/250 - Loss: 1.003   lengthscale: 1.925   noise: 0.436\n",
      "Iter 240/250 - Loss: 1.003   lengthscale: 1.925   noise: 0.436\n",
      "Iter 241/250 - Loss: 1.003   lengthscale: 1.925   noise: 0.436\n",
      "Iter 242/250 - Loss: 1.003   lengthscale: 1.924   noise: 0.436\n",
      "Iter 243/250 - Loss: 1.003   lengthscale: 1.924   noise: 0.436\n",
      "Iter 244/250 - Loss: 1.003   lengthscale: 1.924   noise: 0.436\n",
      "Iter 245/250 - Loss: 1.003   lengthscale: 1.924   noise: 0.436\n",
      "Iter 246/250 - Loss: 1.003   lengthscale: 1.924   noise: 0.436\n",
      "Iter 247/250 - Loss: 1.003   lengthscale: 1.924   noise: 0.436\n",
      "Iter 248/250 - Loss: 1.003   lengthscale: 1.924   noise: 0.436\n",
      "Iter 249/250 - Loss: 1.003   lengthscale: 1.924   noise: 0.436\n",
      "Iter 250/250 - Loss: 1.003   lengthscale: 1.924   noise: 0.436\n"
     ]
    }
   ],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = 2 if smoke_test else 250\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(x_train_data)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, y_train_data)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "        i + 1, training_iter, loss.item(),\n",
    "        model.covar_module.base_kernel.lengthscale.item(),\n",
    "        model.likelihood.noise.item()\n",
    "    ))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45dd539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(x_min, x_max , 51, dtype = torch.double)\n",
    "    observed_pred = likelihood(model(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de0293bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # Initialize plot\n",
    "    f, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = observed_pred.confidence_region()\n",
    "    # Plot training data as black stars\n",
    "    ax.plot(x_train_data.numpy(), y_train_data.numpy(), 'k*')\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x, observed_pred.mean.numpy(), 'b')\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\n",
    "#     ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af395ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
